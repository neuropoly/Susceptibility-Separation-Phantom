{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import gaussian_kde \n",
    "from matplotlib.lines import Line2D    \n",
    "from matplotlib.patches import Patch  \n",
    "from pathlib import Path  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = base_dir = Path.cwd()\n",
    "\n",
    "# Verify that the parent of the entered path exists\n",
    "if not base_dir.parent.exists():\n",
    "    raise FileNotFoundError(f\"The specified path {base_dir.parent} does not exist.\")\n",
    "else:\n",
    "    # Create the last folder if it doesn't exist\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Using data directory: {base_dir}\")\n",
    "!pip install osfclient\n",
    "# Clone the OSF project into the specified directory\n",
    "!osf -p 9xwhz clone \"{base_dir}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of susceptibility anisotropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# Parameters and File Paths\n",
    "# ---------------------------\n",
    "num_algorithms = 4\n",
    "algorithm_names = [\n",
    "    '$\\\\chi$-separation', \n",
    "    'R2*-QSM', \n",
    "    'APART-QSM', \n",
    "    'DECOMPOSE-QSM'\n",
    "]\n",
    "\n",
    "# Load segmentation mask (assumed to contain region labels 1 to 11)\n",
    "segmentation2_path = base_dir / 'osfstorage' / 'Masks' / 'white_matter_mask.nii.gz'\n",
    "segmentation2 = nib.load(segmentation2_path).get_fdata()\n",
    "region_labels = list(range(1, 12))  # regions 1 to 11\n",
    "\n",
    "# Load simulated maps (common for all algorithms)\n",
    "simulated_with_path = base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_negative_with_anisotropy.nii.gz'\n",
    "simulated_without_path = base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_negative.nii.gz'\n",
    "simulated_with = nib.load(simulated_with_path).get_fdata()\n",
    "simulated_without = nib.load(simulated_without_path).get_fdata()\n",
    "\n",
    "# Define measured maps for each algorithm\n",
    "measured_maps = {\n",
    "    0: {  # Algorithm 1: Ï‡-separation\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiNegMap.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'Without_anisotropy' / 'ChiNegMap.nii',\n",
    "    },\n",
    "    1: {  # Algorithm 2: R2*-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'With_anisotropy' / 'ChiNegMap.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'Without_anisotropy' / 'ChiNegMap.nii',\n",
    "    },\n",
    "    2: {  # Algorithm 3: APART-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'With_anisotropy' / 'X_dia_abs.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'Without_anisotropy' / 'X_dia_abs.nii',\n",
    "    },\n",
    "    3: {  # Algorithm 4: DECOMPOSE-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'With_anisotropy' / 'Results_DCS_abs.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'Without_anisotropy' / 'results_DCS_abs.nii',\n",
    "    },\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), dpi=300)\n",
    "t_test_results = {}\n",
    "for idx in range(num_algorithms):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    algorithm_name = algorithm_names[idx]\n",
    "    \n",
    "    measured_with = nib.load(measured_maps[idx]['x_minus_with_anisotropy']).get_fdata() * -1\n",
    "    measured_without = nib.load(measured_maps[idx]['x_minus_without_anisotropy']).get_fdata() * -1\n",
    "\n",
    "    errors_with_regions = []\n",
    "    errors_without_regions = []\n",
    "    \n",
    "    for region in region_labels:\n",
    "        region_mask = segmentation2 == region\n",
    "        if np.any(region_mask):\n",
    "            # For \"With Anisotropy\"\n",
    "            sim_val_with = np.mean(simulated_with[region_mask])\n",
    "            meas_val_with = np.mean(measured_with[region_mask])\n",
    "            if sim_val_with != 0:\n",
    "                error_with = ((meas_val_with - sim_val_with) / sim_val_with) ** 2 * 100\n",
    "            else:\n",
    "                error_with = np.nan\n",
    "            \n",
    "            # For \"Without Anisotropy\"\n",
    "            sim_val_without = np.mean(simulated_without[region_mask])\n",
    "            meas_val_without = np.mean(measured_without[region_mask])\n",
    "            if sim_val_without != 0:\n",
    "                error_without = ((meas_val_without - sim_val_without) / sim_val_without) ** 2 * 100\n",
    "            else:\n",
    "                error_without = np.nan\n",
    "            \n",
    "            errors_with_regions.append(error_with)\n",
    "            errors_without_regions.append(error_without)\n",
    "   \n",
    "    errors_with_regions = np.array(errors_with_regions)\n",
    "    errors_without_regions = np.array(errors_without_regions)\n",
    "    errors_with_regions = errors_with_regions[~np.isnan(errors_with_regions)]\n",
    "    errors_without_regions = errors_without_regions[~np.isnan(errors_without_regions)]\n",
    "\n",
    "    x_vals = np.linspace(0, 70, 200)  \n",
    "    max_height = 0.4  \n",
    "    \n",
    "    # Plot KDE for \"With Anisotropy\"\n",
    "    if errors_with_regions.size > 1:\n",
    "        kde_with = gaussian_kde(errors_with_regions)\n",
    "        density_with = kde_with(x_vals)\n",
    "        scaling_with = max_height / np.max(density_with) if np.max(density_with) > 0 else 1\n",
    "        density_with_scaled = density_with * scaling_with\n",
    "        ax.fill_between(x_vals, 0, density_with_scaled, color='tab:blue', alpha=0.4)\n",
    "        ax.plot(x_vals, density_with_scaled, color='tab:blue', alpha=0.7)\n",
    "        mean_mspe_with = np.mean(errors_with_regions)\n",
    "    elif errors_with_regions.size == 1:\n",
    "        mean_mspe_with = errors_with_regions[0]\n",
    "        ax.plot([mean_mspe_with], [max_height/2], marker='o', color='tab:blue')\n",
    "    else:\n",
    "        mean_mspe_with = None  # no data available\n",
    "\n",
    "    # Plot KDE for \"Without Anisotropy\"\n",
    "    if errors_without_regions.size > 1:\n",
    "        kde_without = gaussian_kde(errors_without_regions)\n",
    "        density_without = kde_without(x_vals)\n",
    "        scaling_without = max_height / np.max(density_without) if np.max(density_without) > 0 else 1\n",
    "        density_without_scaled = density_without * scaling_without\n",
    "        ax.fill_between(x_vals, 0, density_without_scaled, color='tab:orange', alpha=0.4)\n",
    "        ax.plot(x_vals, density_without_scaled, color='tab:orange', alpha=0.7)\n",
    "        mean_mspe_without = np.mean(errors_without_regions)\n",
    "    elif errors_without_regions.size == 1:\n",
    "        mean_mspe_without = errors_without_regions[0]\n",
    "        ax.plot([mean_mspe_without], [max_height/2], marker='o', color='tab:orange')\n",
    "    else:\n",
    "        mean_mspe_without = None\n",
    "\n",
    "    if mean_mspe_with is not None:\n",
    "        ax.text(0.95, 0.8, f\"Mean MSPE: {mean_mspe_with:.1f}%\", transform=ax.transAxes,\n",
    "                color='tab:blue', ha='right', va='center', fontsize=12)\n",
    "    if mean_mspe_without is not None:\n",
    "        ax.text(0.95, 0.7, f\"Mean MSPE: {mean_mspe_without:.1f}%\", transform=ax.transAxes,\n",
    "                color='tab:orange', ha='right', va='center', fontsize=12)\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # Create and add a legend for the subplot\n",
    "    # ------------------------------------------------\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='tab:blue', lw=2, label='With Anisotropy'),\n",
    "        Line2D([0], [0], color='tab:orange', lw=2, label='Without Anisotropy')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    # Set title and axis labels.\n",
    "    ax.set_title(algorithm_name, fontsize=14)\n",
    "    ax.set_xlabel(\"MSPE of $\\\\chi^-$ (%)\", fontsize=12)\n",
    "    ax.set_ylabel(\"Density (a.u.)\", fontsize=12)\n",
    "    ax.set_xlim(0, 70)\n",
    "    ax.set_ylim(0, max_height * 1.2)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# ---------------------------\n",
    "# Final figure adjustments\n",
    "# ---------------------------\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Define algorithms, SNR levels, and errors\n",
    "# -------------------------------------------\n",
    "algorithms = [\n",
    "    '$\\\\chi$-separation',\n",
    "    'R2*-QSM',\n",
    "    'APART-QSM',\n",
    "    'DECOMPOSE-QSM'\n",
    "]\n",
    "snr_levels = [50, 100, 200, 300]\n",
    "\n",
    "# Initialize dictionaries\n",
    "x_positive_errors = {alg: [] for alg in algorithms}\n",
    "x_negative_errors = {alg: [] for alg in algorithms}\n",
    "\n",
    "def construct_path(*args):\n",
    "    \"\"\"Construct a path with 'osfstorage' as a subdirectory of base_dir.\"\"\"\n",
    "    return base_dir / 'osfstorage' / Path(*args)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Load Simulated Maps\n",
    "# -------------------------------------------\n",
    "simulated_positive_path = construct_path('Susceptibility_Separation_Results', 'Chi_positive.nii.gz')\n",
    "simulated_negative_path = construct_path('Susceptibility_Separation_Results', 'Chi_negative_with_anisotropy.nii.gz')\n",
    "simulated_positive = nib.load(simulated_positive_path).get_fdata()\n",
    "simulated_negative = nib.load(simulated_negative_path).get_fdata()\n",
    "\n",
    "# -------------------------------------------\n",
    "# Load Segmentation Masks\n",
    "# -------------------------------------------\n",
    "segmentation_positive_path = construct_path('Masks', 'SegmentedModel.nii.gz')\n",
    "segmentation_negative_path = construct_path('Masks', 'white_matter_mask.nii.gz')\n",
    "segmentation_positive = nib.load(segmentation_positive_path).get_fdata()\n",
    "segmentation_negative = nib.load(segmentation_negative_path).get_fdata()\n",
    "\n",
    "# -------------------------------------------\n",
    "# Measured Maps: Positive & Negative\n",
    "# -------------------------------------------\n",
    "measured_maps_positive = {\n",
    "    '$\\\\chi$-separation': {\n",
    "        300: construct_path('Noise', 'X-separation', 'SNR_300', 'ChiPosMap.nii.gz'),\n",
    "        200: construct_path('Noise', 'X-separation', 'SNR_200', 'ChiPosMap.nii.gz'),\n",
    "        100: construct_path('Noise', 'X-separation', 'SNR_100', 'ChiPosMap.nii.gz'),\n",
    "        50:  construct_path('Noise', 'X-separation', 'SNR_50',  'ChiPosMap.nii.gz'),\n",
    "    },\n",
    "    'R2*-QSM': {\n",
    "        300: construct_path('Noise', 'R2star-QSM', 'SNR_300', 'ChiPosMap.nii.gz'),\n",
    "        200: construct_path('Noise', 'R2star-QSM', 'SNR_200', 'ChiPosMap.nii.gz'),\n",
    "        100: construct_path('Noise', 'R2star-QSM', 'SNR_100', 'ChiPosMap.nii.gz'),\n",
    "        50:  construct_path('Noise', 'R2star-QSM', 'SNR_50',  'ChiPosMap.nii.gz'),\n",
    "    },\n",
    "    'APART-QSM': {\n",
    "        300: construct_path('Noise', 'APART-QSM', 'SNR_300', 'X_para.nii.gz'),\n",
    "        200: construct_path('Noise', 'APART-QSM', 'SNR_200', 'X_para.nii.gz'),\n",
    "        100: construct_path('Noise', 'APART-QSM', 'SNR_100', 'X_para.nii.gz'),\n",
    "        50:  construct_path('Noise', 'APART-QSM', 'SNR_50',  'X_para.nii.gz'),\n",
    "    },\n",
    "    'DECOMPOSE-QSM': {\n",
    "        300: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_300', 'results_PCS.nii.gz'),\n",
    "        200: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_200', 'results_PCS.nii.gz'),\n",
    "        100: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_100', 'results_PCS.nii.gz'),\n",
    "        50:  construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_50',  'results_PCS.nii.gz'),\n",
    "    },\n",
    "}\n",
    "\n",
    "measured_maps_negative = {\n",
    "    '$\\\\chi$-separation': {\n",
    "        300: construct_path('Noise', 'X-separation', 'SNR_300', 'ChiNegMap.nii.gz'),\n",
    "        200: construct_path('Noise', 'X-separation', 'SNR_200', 'ChiNegMap.nii.gz'),\n",
    "        100: construct_path('Noise', 'X-separation', 'SNR_100', 'ChiNegMap.nii.gz'),\n",
    "        50:  construct_path('Noise', 'X-separation', 'SNR_50',  'ChiNegMap.nii.gz'),\n",
    "    },\n",
    "    'R2*-QSM': {\n",
    "        300: construct_path('Noise', 'R2star-QSM', 'SNR_300', 'ChiNegMap.nii.gz'),\n",
    "        200: construct_path('Noise', 'R2star-QSM', 'SNR_200', 'ChiNegMap.nii.gz'),\n",
    "        100: construct_path('Noise', 'R2star-QSM', 'SNR_100', 'ChiNegMap.nii.gz'),\n",
    "        50:  construct_path('Noise', 'R2star-QSM', 'SNR_50',  'ChiNegMap.nii.gz'),\n",
    "    },\n",
    "    'APART-QSM': {\n",
    "        300: construct_path('Noise', 'APART-QSM', 'SNR_300', 'X_dia_abs.nii.gz'),\n",
    "        200: construct_path('Noise', 'APART-QSM', 'SNR_200', 'X_dia_abs.nii.gz'),\n",
    "        100: construct_path('Noise', 'APART-QSM', 'SNR_100', 'X_dia_abs.nii.gz'),\n",
    "        50:  construct_path('Noise', 'APART-QSM', 'SNR_50',  'X_dia_abs.nii.gz'),\n",
    "    },\n",
    "    'DECOMPOSE-QSM': {\n",
    "        300: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_300', 'results_DCS_abs.nii.gz'),\n",
    "        200: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_200', 'results_DCS_abs.nii.gz'),\n",
    "        100: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_100', 'results_DCS_abs.nii.gz'),\n",
    "        50:  construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_50',  'results_DCS_abs.nii.gz'),\n",
    "    },\n",
    "}\n",
    "\n",
    "# -------------------------------------------\n",
    "# Compute Errors\n",
    "# -------------------------------------------\n",
    "for alg in algorithms:\n",
    "    for snr in snr_levels:\n",
    "        # Load measured maps (X+ and X-)\n",
    "        measured_positive_path = measured_maps_positive[alg][snr]\n",
    "        measured_negative_path = measured_maps_negative[alg][snr]\n",
    "        \n",
    "        measured_positive = nib.load(measured_positive_path).get_fdata()\n",
    "        measured_negative = nib.load(measured_negative_path).get_fdata()\n",
    "        \n",
    "        # Multiply X- by -1\n",
    "        measured_negative = -1 * measured_negative\n",
    "        \n",
    "        # -----------------------------\n",
    "        # Positive regions: 1 to 9\n",
    "        # -----------------------------\n",
    "        positive_errors = []\n",
    "        for region in range(1, 10):\n",
    "            mask = (segmentation_positive == region)\n",
    "            measured_mean = np.mean(measured_positive[mask])\n",
    "            simulated_mean = np.mean(simulated_positive[mask])\n",
    "            \n",
    "            error = ((measured_mean - simulated_mean) / simulated_mean)**2 * 100\n",
    "            positive_errors.append(error)\n",
    "        \n",
    "        avg_positive_error = np.mean(positive_errors)\n",
    "        x_positive_errors[alg].append(avg_positive_error)\n",
    "        \n",
    "        # -----------------------------\n",
    "        # Negative regions\n",
    "        #   - 1 to 9 (segmentation_positive)\n",
    "        #   - 1 to 10 (segmentation_negative)\n",
    "        # -----------------------------\n",
    "        negative_errors = []\n",
    "        \n",
    "        # 1 to 9\n",
    "        for region in range(1, 10):\n",
    "            mask = (segmentation_positive == region)\n",
    "            measured_mean = np.mean(measured_negative[mask])\n",
    "            simulated_mean = np.mean(simulated_negative[mask])\n",
    "            \n",
    "            error = ((measured_mean - simulated_mean) / simulated_mean)**2 * 100\n",
    "            negative_errors.append(error)\n",
    "        \n",
    "        # 1 to 10 (segmentation_negative)\n",
    "        for region in range(1, 11):\n",
    "            mask = (segmentation_negative == region)\n",
    "            measured_mean = np.mean(measured_negative[mask])\n",
    "            simulated_mean = np.mean(simulated_negative[mask])\n",
    "            \n",
    "            error = ((measured_mean - simulated_mean) / simulated_mean)**2 * 100\n",
    "            negative_errors.append(error)\n",
    "        \n",
    "        avg_negative_error = np.mean(negative_errors)\n",
    "        x_negative_errors[alg].append(avg_negative_error)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Plotting\n",
    "# -------------------------------------------\n",
    "hatch_patterns = ['x', 'o', '*', '+']\n",
    "snr_colors = {\n",
    "    50:  '#66c2a5',\n",
    "    100: '#8da0cb',\n",
    "    200: '#fc8d62',\n",
    "    300: '#e78ac3',\n",
    "}\n",
    "\n",
    "bar_width = 0.2\n",
    "snr_index = np.arange(len(snr_levels))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), dpi=600)\n",
    "\n",
    "tick_font_size = 14\n",
    "\n",
    "# --- Plot Ï‡+ ---\n",
    "for i, (alg, hatch) in enumerate(zip(algorithms, hatch_patterns)):\n",
    "    for j, snr in enumerate(snr_levels):\n",
    "        x_coord = snr_index[j] + i * bar_width\n",
    "        y_value = x_positive_errors[alg][j]\n",
    "        \n",
    "        \n",
    "        ax1.bar(\n",
    "            x_coord,\n",
    "            y_value,\n",
    "            bar_width,\n",
    "            hatch=hatch,\n",
    "            edgecolor='black',\n",
    "            color=snr_colors[snr],\n",
    "        )\n",
    "\n",
    "ax1.set_xlabel('SNR (a.u.)', fontsize=tick_font_size)\n",
    "ax1.set_ylabel('MSPE of $\\\\chi^+$ (%)', fontsize=tick_font_size)\n",
    "ax1.set_xticks(snr_index + bar_width * 1.5)\n",
    "ax1.set_xticklabels(snr_levels, fontsize=tick_font_size)\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=tick_font_size)\n",
    "\n",
    "# --- Plot Ï‡- ---\n",
    "for i, (alg, hatch) in enumerate(zip(algorithms, hatch_patterns)):\n",
    "    for j, snr in enumerate(snr_levels):\n",
    "        x_coord = snr_index[j] + i * bar_width\n",
    "        y_value = x_negative_errors[alg][j]\n",
    "        \n",
    "        \n",
    "        ax2.bar(\n",
    "            x_coord,\n",
    "            y_value,\n",
    "            bar_width,\n",
    "            hatch=hatch,\n",
    "            edgecolor='black',\n",
    "            color=snr_colors[snr],\n",
    "        )\n",
    "\n",
    "ax2.set_xlabel('SNR (a.u.)', fontsize=tick_font_size)\n",
    "ax2.set_ylabel('MSPE of $\\\\chi^-$ (%)', fontsize=tick_font_size)\n",
    "ax2.set_xticks(snr_index + bar_width * 1.5)\n",
    "ax2.set_xticklabels(snr_levels, fontsize=tick_font_size)\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=tick_font_size)\n",
    "\n",
    "\n",
    "# For Ï‡+ axis:\n",
    "algorithm_patches_pos = []\n",
    "for alg, hatch in zip(algorithms, hatch_patterns):\n",
    "    patch = Patch(\n",
    "        facecolor='white',   \n",
    "        edgecolor='black',   \n",
    "        hatch=hatch,         \n",
    "        label=alg\n",
    "    )\n",
    "    algorithm_patches_pos.append(patch)\n",
    "\n",
    "ax1.legend(\n",
    "    handles=algorithm_patches_pos,\n",
    "    fontsize=14,\n",
    "    facecolor='white',\n",
    "    framealpha=1,\n",
    "    loc='upper right',     \n",
    "    handlelength=1.5,\n",
    "    handleheight=1.5\n",
    ")\n",
    "\n",
    "# For Ï‡- axis:\n",
    "algorithm_patches_neg = []\n",
    "for alg, hatch in zip(algorithms, hatch_patterns):\n",
    "    patch = Patch(\n",
    "        facecolor='white',\n",
    "        edgecolor='black',\n",
    "        hatch=hatch,\n",
    "        label=alg\n",
    "    )\n",
    "    algorithm_patches_neg.append(patch)\n",
    "\n",
    "ax2.legend(\n",
    "    handles=algorithm_patches_neg,\n",
    "    fontsize=14,\n",
    "    facecolor='white',\n",
    "    framealpha=1,\n",
    "    loc='upper right',     \n",
    "    handlelength=1.5,\n",
    "    handleheight=1.5\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of noise on susceptibility anisotorpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the algorithms and SNR levels\n",
    "algorithms = ['x-separation', 'R2*-QSM', 'APART-QSM', 'DECOMPOSE-QSM']\n",
    "snr_levels = ['SNR 300', 'SNR 200', 'SNR 100', 'SNR 50']\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store the full paths for measured images\n",
    "measured_image_paths = {\n",
    "    'x-separation': {\n",
    "        'SNR 300': base_dir / 'osfstorage' / 'Noise' / 'X-separation' / 'SNR_300' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 200': base_dir / 'osfstorage' / 'Noise' / 'X-separation' / 'SNR_200' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 100': base_dir / 'osfstorage' / 'Noise' / 'X-separation' / 'SNR_100' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 50': base_dir / 'osfstorage' / 'Noise' / 'X-separation' / 'SNR_50' / 'ChiNegMap.nii.gz',\n",
    "    },\n",
    "    'R2*-QSM': {\n",
    "        'SNR 300': base_dir / 'osfstorage' / 'Noise' / 'R2star-QSM' / 'SNR_300' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 200': base_dir / 'osfstorage' / 'Noise' / 'R2star-QSM' / 'SNR_200' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 100': base_dir / 'osfstorage' / 'Noise' / 'R2star-QSM' / 'SNR_100' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 50': base_dir / 'osfstorage' / 'Noise' / 'R2star-QSM' / 'SNR_50' / 'ChiNegMap.nii.gz',\n",
    "    },\n",
    "    'APART-QSM': {\n",
    "        'SNR 300': base_dir / 'osfstorage' / 'Noise' / 'APART-QSM' / 'SNR_300' / 'X_dia_abs.nii.gz',\n",
    "        'SNR 200': base_dir / 'osfstorage' / 'Noise' / 'APART-QSM' / 'SNR_200' / 'X_dia_abs.nii.gz',\n",
    "        'SNR 100': base_dir / 'osfstorage' / 'Noise' / 'APART-QSM' / 'SNR_100' / 'X_dia_abs.nii.gz',\n",
    "        'SNR 50': base_dir / 'osfstorage' / 'Noise' / 'APART-QSM' / 'SNR_50' / 'X_dia_abs.nii.gz',\n",
    "    },\n",
    "    'DECOMPOSE-QSM': {\n",
    "        'SNR 300': base_dir / 'osfstorage' / 'Noise' / 'DECOMPOSE-QSM' / 'SNR_300' / 'results_DCS_abs.nii.gz',\n",
    "        'SNR 200': base_dir / 'osfstorage' / 'Noise' / 'DECOMPOSE-QSM' / 'SNR_200' / 'results_DCS_abs.nii.gz',\n",
    "        'SNR 100': base_dir / 'osfstorage' / 'Noise' / 'DECOMPOSE-QSM' / 'SNR_100' / 'results_DCS_abs.nii.gz',\n",
    "        'SNR 50': base_dir / 'osfstorage' / 'Noise' / 'DECOMPOSE-QSM' / 'SNR_50' / 'results_DCS_abs.nii.gz',\n",
    "    },\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) LOAD NIFTI DATA\n",
    "# ----------------------------\n",
    "\n",
    "# Load simulated (ground truth) chi, theta, and segmentation images\n",
    "simulated_nii = nib.load(base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_negative_with_anisotropy.nii.gz')\n",
    "simulated_img_with_anisotropy = simulated_nii.get_fdata()\n",
    "\n",
    "theta_nii = nib.load(base_dir / 'osfstorage' / 'Noise' / 'theta.nii.gz')\n",
    "theta_img = theta_nii.get_fdata()\n",
    "theta_img[np.isnan(theta_img)] = 0\n",
    "\n",
    "segmentation_nii = nib.load(base_dir / 'osfstorage' / 'Masks' / 'WM_fibers_seg.nii.gz')\n",
    "segmentation_img = segmentation_nii.get_fdata()\n",
    "\n",
    "theta_shape = theta_nii.shape\n",
    "theta_affine = theta_nii.affine\n",
    "\n",
    "# Load measured images for each algorithm and SNR\n",
    "measured_images = {}\n",
    "for algorithm in algorithms:\n",
    "    measured_images[algorithm] = {}\n",
    "    for snr in snr_levels:\n",
    "        path = measured_image_paths[algorithm][snr]\n",
    "        measured_images[algorithm][snr] = nib.load(path).get_fdata()\n",
    "\n",
    "# ----------------------------\n",
    "# 3) GATHER VALID VOXELS & COMPUTE ERRORS\n",
    "# ----------------------------\n",
    "\n",
    "all_valid_coords = []  \n",
    "all_theta_values = []\n",
    "all_sim_values = []\n",
    "\n",
    "errors = {\n",
    "    algorithm: {\n",
    "        snr: [] for snr in snr_levels\n",
    "    }\n",
    "    for algorithm in algorithms\n",
    "}\n",
    "\n",
    "# Loop over the segmentation regions \n",
    "for region in range(1, 28):\n",
    "    # Region mask\n",
    "    region_mask = (segmentation_img == region)\n",
    "    region_valid_mask = region_mask & (theta_img != 0)\n",
    "    \n",
    "    # Get the 3D coordinates of those valid voxels\n",
    "    valid_coords = np.argwhere(region_valid_mask)\n",
    "    if valid_coords.size == 0:\n",
    "        continue  \n",
    "\n",
    "    # Extract the actual voxel values\n",
    "    region_theta_vals = theta_img[region_valid_mask]\n",
    "    region_sim_vals = simulated_img_with_anisotropy[region_valid_mask] * -1\n",
    "\n",
    "    # Append these to our global lists\n",
    "    all_valid_coords.append(valid_coords)\n",
    "    all_theta_values.append(region_theta_vals)\n",
    "    all_sim_values.append(region_sim_vals)\n",
    "\n",
    "    # For each algorithm & SNR, calculate MSPE in this region and append\n",
    "    for algorithm in algorithms:\n",
    "        for snr in snr_levels:\n",
    "            measured_vals = measured_images[algorithm][snr][region_valid_mask]\n",
    "            epsilon = 1e-10  \n",
    "            relative_squared_error = np.sqrt(\n",
    "            np.square(region_sim_vals - measured_vals) /\n",
    "            (np.square(region_sim_vals) + epsilon)\n",
    "            ) * 100\n",
    "            errors[algorithm][snr].append(relative_squared_error)\n",
    "\n",
    "all_valid_coords = np.concatenate(all_valid_coords, axis=0)\n",
    "all_theta_values = np.concatenate(all_theta_values, axis=0)\n",
    "all_sim_values = np.concatenate(all_sim_values, axis=0)\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    for snr in snr_levels:\n",
    "        errors[algorithm][snr] = np.concatenate(errors[algorithm][snr], axis=0)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) BIN THE THETA VALUES \n",
    "# ----------------------------\n",
    "\n",
    "bins = np.arange(0, 100, 10)  \n",
    "\n",
    "bin_indices = np.digitize(all_theta_values, bins)  \n",
    "num_bins = len(bins) - 1  \n",
    "\n",
    "# Calculate the mean bin angle\n",
    "bin_means_theta = []\n",
    "for b in range(1, len(bins)):\n",
    "    mask_b = (bin_indices == b)\n",
    "    if np.any(mask_b):\n",
    "        bin_means_theta.append(np.mean(all_theta_values[mask_b]))\n",
    "bin_means_theta = np.array(bin_means_theta)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) CALCULATE BIN MEANS OF MSPE FOR EACH ALGORITHM AND SNR\n",
    "# ----------------------------\n",
    "\n",
    "bin_means = {\n",
    "    algorithm: {\n",
    "        snr: [] for snr in snr_levels\n",
    "    } for algorithm in algorithms\n",
    "}\n",
    "\n",
    "for b in range(1, len(bins)):\n",
    "    mask_b = (bin_indices == b)\n",
    "    if np.any(mask_b):\n",
    "        for algorithm in algorithms:\n",
    "            for snr in snr_levels:\n",
    "                mspe_values_bin = errors[algorithm][snr][mask_b]\n",
    "                bin_mean_error = np.mean(mspe_values_bin)\n",
    "                bin_means[algorithm][snr].append(bin_mean_error)\n",
    "    else:\n",
    "        \n",
    "        for algorithm in algorithms:\n",
    "            for snr in snr_levels:\n",
    "                bin_means[algorithm][snr].append(np.nan)\n",
    "\n",
    "# Convert bin means to numpy arrays\n",
    "for algorithm in algorithms:\n",
    "    for snr in snr_levels:\n",
    "        bin_means[algorithm][snr] = np.array(bin_means[algorithm][snr])\n",
    "\n",
    "# ----------------------------\n",
    "# 6) SAVE A SINGLE 3D MASK WITH BIN LABELS\n",
    "# ----------------------------\n",
    "\n",
    "all_bins_3d = np.zeros(theta_shape, dtype=np.uint8)\n",
    "\n",
    "for b in range(1, len(bins)):\n",
    "    # Voxels in bin b\n",
    "    mask_b = (bin_indices == b)\n",
    "    \n",
    "    # Coordinates of voxels in bin b\n",
    "    bin_coords = all_valid_coords[mask_b]\n",
    "    all_bins_3d[bin_coords[:, 0], bin_coords[:, 1], bin_coords[:, 2]] = b\n",
    "\n",
    "# ----------------------------\n",
    "# 7) PLOT THE RESULTS\n",
    "# ----------------------------\n",
    "\n",
    "markers = {\n",
    "    'SNR 300': ('#e78ac3', 'o'),\n",
    "    'SNR 200': ('#fc8d62', 'o'),\n",
    "    'SNR 100': ('#8da0cb', 'o'),\n",
    "    'SNR 50': ('#66c2a5', 'o')\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "algorithm_subplot_indices = {\n",
    "    'x-separation': (0, 0),\n",
    "    'R2*-QSM': (0, 1),\n",
    "    'APART-QSM': (1, 0),\n",
    "    'DECOMPOSE-QSM': (1, 1)\n",
    "}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    ax = axs[algorithm_subplot_indices[algorithm]]\n",
    "    \n",
    "    # Dictionary to store percentage changes for each SNR\n",
    "    percentage_changes = {}\n",
    "    \n",
    "    for snr in snr_levels:\n",
    "        color, marker = markers[snr]\n",
    "        \n",
    "        # x-values = bin_means_theta\n",
    "        x_vals = bin_means_theta\n",
    "        # y-values = bin_means[algorithm][snr]\n",
    "        y_vals = bin_means[algorithm][snr]\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax.scatter(\n",
    "            x_vals,\n",
    "            y_vals,\n",
    "            color=color,\n",
    "            marker=marker,\n",
    "            label=snr\n",
    "        )\n",
    "        \n",
    "        # 1) Sort the points by x so we can connect them in ascending order\n",
    "        sort_idx = np.argsort(x_vals)\n",
    "        x_sorted = x_vals[sort_idx]\n",
    "        y_sorted = y_vals[sort_idx]\n",
    "       \n",
    "        # Calculate percentage change (max vs. min) for this SNR\n",
    "        valid_mspe = y_vals[~np.isnan(y_vals)]\n",
    "        if len(valid_mspe) > 0:\n",
    "            max_mspe = y_vals[0]\n",
    "            min_mspe = y_vals[-1]\n",
    "            if max_mspe != 0:\n",
    "                percentage_change = (max_mspe - min_mspe) / max_mspe * 100\n",
    "            else:\n",
    "                percentage_change = 0\n",
    "        else:\n",
    "            percentage_change = 0\n",
    "        \n",
    "        percentage_changes[snr] = percentage_change\n",
    "\n",
    "    # Build the \"MEV=\" Variation text with Matplotlib colors\n",
    "    x_position = 0.47\n",
    "    y_position = 0.05\n",
    "\n",
    "    ax.text(\n",
    "        x_position, y_position,\n",
    "        \"MEV=\",\n",
    "        transform=ax.transAxes, fontsize=12, color='black', ha='left', va='top'\n",
    "    )\n",
    "    x_position += 0.1\n",
    "\n",
    "    text_colors = ['#e78ac3', '#fc8d62', '#8da0cb', '#66c2a5']\n",
    "    for idx, snr in enumerate(snr_levels):\n",
    "        color_ = text_colors[idx]\n",
    "        ax.text(\n",
    "            x_position, y_position,\n",
    "            f\"{percentage_changes[snr]:.1f}%\",\n",
    "            transform=ax.transAxes, fontsize=12, color=color_, ha='left', va='top'\n",
    "        )\n",
    "        x_position += 0.1\n",
    "\n",
    "    # Set titles and labels\n",
    "    if algorithm == 'x-separation':\n",
    "        ax.set_title(r\"$\\chi$-separation\")\n",
    "    else:\n",
    "        ax.set_title(algorithm)\n",
    "\n",
    "    ax.set_xlabel('Angle of Orientation (degrees)', fontsize=16)\n",
    "    ax.set_ylabel('MSPE of $\\\\chi^-$ (%)', fontsize=16)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 130)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between simulated vs in-vivo susceptibility maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regions of interest\n",
    "regions_of_interest = [1, 2, 3, 7, 8, 9]\n",
    "\n",
    "# Function to extract mean values per region\n",
    "def extract_mean_per_region(data_map, segmentation_map, regions):\n",
    "    means = []\n",
    "    for region in regions:\n",
    "        region_mask = segmentation_map == region\n",
    "        if np.any(region_mask):\n",
    "            mean_value = np.mean(data_map[region_mask])\n",
    "            means.append(mean_value)\n",
    "        else:\n",
    "            means.append(np.nan)\n",
    "    return means\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Load segmentation map (for simulated data only)\n",
    "# ------------------------------------------------------------------------------\n",
    "segmentation_simulated = nib.load(\n",
    "    base_dir / 'osfstorage' / 'Masks' / 'SegmentedModel.nii.gz'\n",
    ").get_fdata()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Hard-coded in-vivo mean values (from your table) for each algorithm and region\n",
    "# ------------------------------------------------------------------------------\n",
    "# Chi-positive in-vivo data\n",
    "chi_positive_in_vivo_data = {\n",
    "    'chi-separation': [0.0658392,0.113222,0.0550474,0.0475523,0.0270498,0.0299241],\n",
    "    'R2*-QSM':        [0.0357698,0.0610981,0.0347473,0.0265003,0.0159944,0.0140221],\n",
    "    'APART-QSM':      [0.0482199,0.0813391,0.0435077,0.0346825,0.0205208,0.02208],\n",
    "    'DECOMPOSE-QSM':  [0.0337807,0.0538997,0.0325998,0.0301356,0.0157292,0.0112171]\n",
    "}\n",
    "\n",
    "# Chi-negative in-vivo data (already positive)\n",
    "chi_negative_in_vivo_data = {\n",
    "    'chi-separation': [-0.0175603,-0.0332972,-0.0260955,-0.0270215,-0.0303985,-0.0277441],\n",
    "    'R2*-QSM':        [-0.00613275,-0.00185815,-0.00892519,-0.0140371,-0.0187294,-0.0130369],\n",
    "    'APART-QSM':      [-0.0105914,-0.0195933,-0.0182477,-0.0190805,-0.0222699,-2.15E-02],\n",
    "    'DECOMPOSE-QSM':  [-0.00877939,-0.00756195,-0.00899253,-0.00902613,-0.0163517,-0.00915724]\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Initialize dictionaries to store mean values\n",
    "# ------------------------------------------------------------------------------\n",
    "chi_positive_in_vivo_means = {}\n",
    "chi_positive_simulated_means = {}\n",
    "chi_negative_in_vivo_means = {}\n",
    "chi_negative_simulated_means = {}\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# File paths for simulated data\n",
    "# ------------------------------------------------------------------------------\n",
    "chi_positive_simulated_files = {\n",
    "    'chi-separation': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiPosMap.nii',\n",
    "    'R2*-QSM':        base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM'   / 'With_anisotropy' / 'ChiPosMap.nii',\n",
    "    'APART-QSM':      base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM'    / 'With_anisotropy' / 'X_para.nii',\n",
    "    'DECOMPOSE-QSM':  base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM'/ 'With_anisotropy' / 'Results_PCS.nii'\n",
    "}\n",
    "\n",
    "chi_negative_simulated_files = {\n",
    "    'chi-separation': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiNegMap.nii',\n",
    "    'R2*-QSM':        base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM'   / 'With_anisotropy' / 'ChiNegMap.nii',\n",
    "    'APART-QSM':      base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM'    / 'With_anisotropy' / 'X_dia_abs.nii',\n",
    "    'DECOMPOSE-QSM':  base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM'/ 'With_anisotropy' / 'Results_DCS_abs.nii'\n",
    "}\n",
    "\n",
    "algorithms = list(chi_positive_simulated_files.keys())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Process chi-positive data\n",
    "# ------------------------------------------------------------------------------\n",
    "for algo in algorithms:\n",
    "    # In-vivo: use the hard-coded values\n",
    "    in_vivo_means = chi_positive_in_vivo_data[algo]\n",
    "    # Simulated: load from file and extract\n",
    "    simulated_map = nib.load(chi_positive_simulated_files[algo]).get_fdata()\n",
    "    simulated_means = extract_mean_per_region(simulated_map, segmentation_simulated, regions_of_interest)\n",
    "\n",
    "    chi_positive_in_vivo_means[algo] = in_vivo_means\n",
    "    chi_positive_simulated_means[algo] = simulated_means\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Process chi-negative data\n",
    "# ------------------------------------------------------------------------------\n",
    "for algo in algorithms:\n",
    "    # In-vivo: use the hard-coded values\n",
    "    in_vivo_means = chi_negative_in_vivo_data[algo]\n",
    "    # Simulated: load from file, multiply by -1\n",
    "    simulated_map = nib.load(chi_negative_simulated_files[algo]).get_fdata()\n",
    "    simulated_map *= -1\n",
    "    simulated_means = extract_mean_per_region(simulated_map, segmentation_simulated, regions_of_interest)\n",
    "\n",
    "    chi_negative_in_vivo_means[algo] = in_vivo_means\n",
    "    chi_negative_simulated_means[algo] = simulated_means\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Define display names\n",
    "# ------------------------------------------------------------------------------\n",
    "display_names = {\n",
    "    'chi-separation': r'$\\chi$-separation',\n",
    "    'R2*-QSM':        'R2*-QSM',\n",
    "    'APART-QSM':      'APART-QSM',\n",
    "    'DECOMPOSE-QSM':  'DECOMPOSE-QSM'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Plotting function\n",
    "# ------------------------------------------------------------------------------\n",
    "def plot_data(in_vivo_means_dict, simulated_means_dict, chi_type, ax):\n",
    "    marker_styles = ['x', 'o', '*', '+']  # for the 4 algorithms in the order they appear in 'algorithms'\n",
    "\n",
    "    for idx, algo in enumerate(algorithms):\n",
    "        x = np.array(in_vivo_means_dict[algo])\n",
    "        y = np.array(simulated_means_dict[algo])\n",
    "\n",
    "        mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "        x = x[mask]\n",
    "        y = y[mask]\n",
    "\n",
    "        if len(x) > 1:\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "            r_label = rf\"($\it{{r}}$ = {r_value:.2f})\"\n",
    "            sorted_indices = np.argsort(x)\n",
    "            x_sorted = x[sorted_indices]\n",
    "            y_sorted = intercept + slope * x_sorted\n",
    "            ax.plot(x_sorted, y_sorted, color='black', linestyle='--', label=None)\n",
    "        else:\n",
    "            r_label = \"(RÂ²=NaN)\"\n",
    "\n",
    "        label = f\"{display_names[algo]} {r_label}\"\n",
    "        marker = marker_styles[idx]\n",
    "\n",
    "        if marker == 'x':\n",
    "            ax.scatter(x, y, marker=marker, s=80, color='black',\n",
    "                       linewidth=1.5, label=label)\n",
    "        elif marker == 'o':\n",
    "            ax.scatter(x, y, marker=marker, s=80,\n",
    "                       edgecolors='black', facecolors='none',\n",
    "                       linewidth=1.5, label=label)\n",
    "        else:\n",
    "            ax.scatter(x, y, marker=marker, s=80,\n",
    "                       color='black', linewidth=1.5, label=label)\n",
    "\n",
    "    x_limits = ax.get_xlim()\n",
    "    y_limits = ax.get_ylim()\n",
    "    min_val = min(x_limits[0], y_limits[0])\n",
    "    max_val = max(x_limits[1], y_limits[1])\n",
    "    ax.set_xlim([min_val, max_val])\n",
    "    ax.set_ylim([min_val, max_val])\n",
    "\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], '-', color='grey', alpha=0.3)\n",
    "    ax.set_xlabel(f'Measured {chi_type} in-vivo (ppm)', fontsize=18)\n",
    "    ax.set_ylabel(f'Simulated {chi_type} (ppm)', fontsize=18)\n",
    "    ax.legend(loc='upper left', fontsize=14)\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Create the figure and subplots\n",
    "# ------------------------------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "plot_data(chi_positive_in_vivo_means, chi_positive_simulated_means, r'$\\chi^+$', axes[0])\n",
    "plot_data(chi_negative_in_vivo_means, chi_negative_simulated_means, r'$\\chi^-$', axes[1])\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between simulated vs in-vivo field maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct file paths relative to the identified base directory\n",
    "simulated_map_path = base_dir / \"osfstorage/LocalField/Simulated_Field.nii.gz\"\n",
    "segmentation_map_path = base_dir / \"osfstorage/Masks/white_matter_mask.nii.gz\"\n",
    "\n",
    "# Load the NIfTI files for simulated local field map and the segmentation map\n",
    "simulated_map_nii = nib.load(simulated_map_path)\n",
    "segmentation_map_nii = nib.load(segmentation_map_path)\n",
    "\n",
    "# Extract the data arrays\n",
    "simulated_map = simulated_map_nii.get_fdata()\n",
    "segmentation_map = segmentation_map_nii.get_fdata()\n",
    "\n",
    "# Extract simulated values for scatter plot (regions 1 to 10 in the segmentation map)\n",
    "simulated_values = []\n",
    "for region in range(1, 11):\n",
    "    region_mask = segmentation_map == region\n",
    "    simulated_region_values = simulated_map[region_mask]\n",
    "    simulated_values.append(np.mean(simulated_region_values))\n",
    "\n",
    "# Hard-coded in-vivo values (for the same 10 regions)\n",
    "in_vivo_values = np.array([\n",
    "    1.74348,\n",
    "    -1.72861,\n",
    "    -1.59869,\n",
    "    1.46938,\n",
    "    -2.61981,\n",
    "    -0.557609,\n",
    "    -0.714494,\n",
    "    -1.31104,\n",
    "    -2.75768,\n",
    "    0.288124\n",
    "])\n",
    "\n",
    "# Scatter plot with linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(in_vivo_values, simulated_values)\n",
    "regression_line = slope * in_vivo_values + intercept\n",
    "\n",
    "# Create the scatter plot with a smaller figure size\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Sort the x-values (in-vivo local field values) and calculate corresponding y-values\n",
    "sorted_indices = np.argsort(in_vivo_values)\n",
    "sorted_in_vivo_values = in_vivo_values[sorted_indices]\n",
    "sorted_regression_line = slope * sorted_in_vivo_values + intercept\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(in_vivo_values, simulated_values, color='black', zorder=2)\n",
    "\n",
    "# Plot the regression line\n",
    "ax.plot(sorted_in_vivo_values, sorted_regression_line, linestyle='--',\n",
    "        color='black', linewidth=1.2, zorder=1)\n",
    "\n",
    "# Add labels, grid, and RÂ² text\n",
    "ax.set_xlabel('In-vivo local field (Hz)', fontsize=10)\n",
    "ax.set_ylabel('Simulated local field (Hz)', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.text(0.05, 0.95,\n",
    "        f'Correlation = {r_value:.2f}\\nSlope = {slope:.1f}',\n",
    "        ha='left', va='top', transform=ax.transAxes, fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between simulated vs in-vivo T2 maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for simulated T2 map and segmentation map\n",
    "simulated_t2_path = base_dir / \"osfstorage/T2/T2_simulated_resampled.nii.gz\"\n",
    "simulated_segmentation_path = base_dir / \"osfstorage/Masks/SegmentedModel_resampled.nii.gz\"\n",
    "\n",
    "# Load NIfTI files for simulated data\n",
    "simulated_t2_map = nib.load(simulated_t2_path).get_fdata()\n",
    "simulated_segmentation = nib.load(simulated_segmentation_path).get_fdata()\n",
    "\n",
    "# Replace NaN and Inf values with 0 in the simulated T2 map\n",
    "simulated_t2_map = np.nan_to_num(simulated_t2_map, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# Hard-coded in-vivo T2 values for regions 1-3 and 7-9 (6 regions)\n",
    "T2_in_vivo = np.array([67.2624, 44.9122, 52.7201, 59.789, 54.5211, 104.057])\n",
    "\n",
    "# Extract simulated T2 values for regions 1-3 and 7-9\n",
    "T2_simulated = []\n",
    "for region in list(range(1, 4)) + list(range(7, 10)):\n",
    "    simulated_mask = simulated_segmentation == region\n",
    "    if np.any(simulated_mask):\n",
    "        simulated_mean = np.mean(simulated_t2_map[simulated_mask])\n",
    "        T2_simulated.append(simulated_mean)\n",
    "T2_simulated = np.array(T2_simulated)\n",
    "\n",
    "# Reshape data for linear regression\n",
    "T2_in_vivo_reshaped = T2_in_vivo.reshape(-1, 1)\n",
    "T2_simulated_reshaped = T2_simulated.reshape(-1, 1)\n",
    "\n",
    "# Perform linear regression\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(T2_in_vivo_reshaped, T2_simulated_reshaped)\n",
    "slope = reg_model.coef_[0][0]\n",
    "intercept = reg_model.intercept_[0]\n",
    "\n",
    "# Generate regression line values\n",
    "x_fit = np.linspace(T2_in_vivo.min(), T2_in_vivo.max(), 100)\n",
    "y_fit = slope * x_fit + intercept\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(T2_in_vivo, T2_simulated, color='black', label='Data Points')\n",
    "plt.plot(x_fit, y_fit, '--', color='black', label='Regression Line')\n",
    "plt.xlabel(r'$T_2^{\\mathrm{in-vivo}}$ (ms)', fontsize=16)\n",
    "plt.ylabel(r'$T_2^{\\mathrm{simulated}}$ (ms)', fontsize=16)\n",
    "\n",
    "correlation = np.corrcoef(T2_in_vivo, T2_simulated)[0, 1]\n",
    "plt.text(45, 120, f'Correlation: {correlation:.2f}\\nSlope: {slope:.2f}', fontsize=18)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplimantary Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_algorithms = 4\n",
    "algorithm_names = [\n",
    "    '$\\\\chi$-separation',\n",
    "    'R2*-QSM',\n",
    "    'APART-QSM',\n",
    "    'DECOMPOSE-QSM'\n",
    "]\n",
    "\n",
    "segmentation2_path = base_dir / 'osfstorage' / 'Masks' / 'white_matter_mask.nii.gz'\n",
    "segmentation2 = nib.load(segmentation2_path).get_fdata()\n",
    "\n",
    "region_labels = list(range(1, 10)) \n",
    "\n",
    "# Load simulated maps \n",
    "simulated_with_path = base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_positive.nii.gz'\n",
    "simulated_without_path = base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_positive.nii.gz'\n",
    "\n",
    "simulated_with = nib.load(simulated_with_path).get_fdata()\n",
    "simulated_without = nib.load(simulated_without_path).get_fdata()\n",
    "\n",
    "# Define measured maps for each algorithm\n",
    "measured_maps = {\n",
    "    0: {  # Algorithm 1: Ï‡-separation\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiPosMap.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'Without_anisotropy' / 'ChiPosMap.nii',\n",
    "    },\n",
    "    1: {  # Algorithm 2: R2*-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'With_anisotropy' / 'ChiPosMap.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'Without_anisotropy' / 'ChiPosMap.nii',\n",
    "    },\n",
    "    2: {  # Algorithm 3: APART-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'With_anisotropy' / 'X_para.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'Without_anisotropy' / 'X_para.nii',\n",
    "    },\n",
    "    3: {  # Algorithm 4: DECOMPOSE-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'With_anisotropy' / 'Results_PCS.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'Without_anisotropy' / 'results_PCS.nii',\n",
    "    },\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), dpi=300)\n",
    "\n",
    "for idx in range(num_algorithms):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    algorithm_name = algorithm_names[idx]\n",
    "    \n",
    "    # Load the measured maps for the current algorithm\n",
    "    measured_with = nib.load(measured_maps[idx]['x_minus_with_anisotropy']).get_fdata() \n",
    "    measured_without = nib.load(measured_maps[idx]['x_minus_without_anisotropy']).get_fdata() \n",
    "    errors_with_regions = []\n",
    "    errors_without_regions = []\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # 1) Compute errors \n",
    "    # --------------------------------------------------\n",
    "    for region in region_labels:\n",
    "        region_mask = (segmentation2 == region)\n",
    "        if region == 8:\n",
    "            continue\n",
    "        \n",
    "        if np.any(region_mask):\n",
    "            # \"With Anisotropy\"\n",
    "            sim_val_with = np.mean(simulated_with[region_mask])\n",
    "           \n",
    "            if sim_val_with < 0:\n",
    "                sim_val_with *= -1\n",
    "            meas_val_with = np.mean(measured_with[region_mask])\n",
    "            if sim_val_with != 0:\n",
    "                error_with = ((meas_val_with - sim_val_with) / sim_val_with) ** 2 * 100\n",
    "            else:\n",
    "                error_with = np.nan\n",
    "\n",
    "            # \"Without Anisotropy\"\n",
    "            sim_val_without = np.mean(simulated_without[region_mask])\n",
    "            meas_val_without = np.mean(measured_without[region_mask])\n",
    "            if sim_val_without != 0:\n",
    "                error_without = ((meas_val_without - sim_val_without) / sim_val_without) ** 2 * 100\n",
    "            else:\n",
    "                error_without = np.nan\n",
    "\n",
    "            errors_with_regions.append(error_with)\n",
    "            errors_without_regions.append(error_without)\n",
    "    \n",
    "    # Convert to numpy arrays and remove NaNs\n",
    "    errors_with_regions = np.array(errors_with_regions)\n",
    "    errors_without_regions = np.array(errors_without_regions)\n",
    "    errors_with_regions = errors_with_regions[~np.isnan(errors_with_regions)]\n",
    "    errors_without_regions = errors_without_regions[~np.isnan(errors_without_regions)]\n",
    "    \n",
    "    # Prepare for KDE\n",
    "    x_vals = np.linspace(0, 30000, 200)  \n",
    "    max_height = 0.4  \n",
    "    \n",
    "    # Plot KDE for \"With Anisotropy\"\n",
    "    if errors_with_regions.size > 1:\n",
    "        kde_with = gaussian_kde(errors_with_regions)\n",
    "        density_with = kde_with(x_vals)\n",
    "        scaling_with = max_height / np.max(density_with) if np.max(density_with) > 0 else 1\n",
    "        density_with_scaled = density_with * scaling_with\n",
    "        ax.fill_between(x_vals, 0, density_with_scaled, alpha=0.4, color='tab:blue')\n",
    "        ax.plot(x_vals, density_with_scaled, alpha=0.7, color='tab:blue')\n",
    "        mean_mspe_with = np.mean(errors_with_regions)\n",
    "    elif errors_with_regions.size == 1:\n",
    "        mean_mspe_with = errors_with_regions[0]\n",
    "        ax.plot([mean_mspe_with], [max_height/2], marker='o', color='tab:blue')\n",
    "    else:\n",
    "        mean_mspe_with = None\n",
    "\n",
    "    # Plot KDE for \"Without Anisotropy\"\n",
    "    if errors_without_regions.size > 1:\n",
    "        kde_without = gaussian_kde(errors_without_regions)\n",
    "        density_without = kde_without(x_vals)\n",
    "        scaling_without = max_height / np.max(density_without) if np.max(density_without) > 0 else 1\n",
    "        density_without_scaled = density_without * scaling_without\n",
    "        ax.fill_between(x_vals, 0, density_without_scaled, alpha=0.4, color='tab:orange')\n",
    "        ax.plot(x_vals, density_without_scaled, alpha=0.7, color='tab:orange')\n",
    "        mean_mspe_without = np.mean(errors_without_regions)\n",
    "    elif errors_without_regions.size == 1:\n",
    "        mean_mspe_without = errors_without_regions[0]\n",
    "        ax.plot([mean_mspe_without], [max_height/2], marker='o', color='tab:orange')\n",
    "    else:\n",
    "        mean_mspe_without = None\n",
    "    \n",
    "    # Show mean MSPE for with/without anisotropy\n",
    "    if mean_mspe_with is not None:\n",
    "        ax.text(0.95, 0.8, f\"Mean MSPE: {mean_mspe_with:.1f}%\", transform=ax.transAxes,\n",
    "                color='tab:blue', ha='right', va='center', fontsize=12)\n",
    "    if mean_mspe_without is not None:\n",
    "        ax.text(0.95, 0.7, f\"Mean MSPE: {mean_mspe_without:.1f}%\", transform=ax.transAxes,\n",
    "                color='tab:orange', ha='right', va='center', fontsize=12)\n",
    "\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='tab:blue', lw=2, label='With Anisotropy'),\n",
    "        Line2D([0], [0], color='tab:orange', lw=2, label='Without Anisotropy')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    ax.set_title(algorithm_name, fontsize=14)\n",
    "    ax.set_xlabel(\"MSPE of $\\\\chi^+$ (%)\", fontsize=12)\n",
    "    ax.set_ylabel(\"Density (a.u.)\", fontsize=12)\n",
    "    ax.set_ylim(0, max_height * 1.2)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# ---------------------------\n",
    "# Final figure adjustments\n",
    "# ---------------------------\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_algorithms = 4\n",
    "algorithm_names = [\n",
    "    '$\\\\chi$-separation',\n",
    "    'R2*-QSM',\n",
    "    'APART-QSM',\n",
    "    'DECOMPOSE-QSM'\n",
    "]\n",
    "\n",
    "segmentation2_path = base_dir / 'osfstorage' / 'Masks' / 'SegmentedModel.nii.gz'\n",
    "segmentation2 = nib.load(segmentation2_path).get_fdata()\n",
    "\n",
    "region_labels = list(range(1, 10)) \n",
    "\n",
    "# Load simulated maps \n",
    "simulated_with_path = base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_positive.nii.gz'\n",
    "simulated_without_path = base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_positive.nii.gz'\n",
    "\n",
    "simulated_with = nib.load(simulated_with_path).get_fdata()\n",
    "simulated_without = nib.load(simulated_without_path).get_fdata()\n",
    "\n",
    "# Define measured maps for each algorithm\n",
    "measured_maps = {\n",
    "    0: {  # Algorithm 1: Ï‡-separation\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiPosMap.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'Without_anisotropy' / 'ChiPosMap.nii',\n",
    "    },\n",
    "    1: {  # Algorithm 2: R2*-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'With_anisotropy' / 'ChiPosMap.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'Without_anisotropy' / 'ChiPosMap.nii',\n",
    "    },\n",
    "    2: {  # Algorithm 3: APART-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'With_anisotropy' / 'X_para.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'Without_anisotropy' / 'X_para.nii',\n",
    "    },\n",
    "    3: {  # Algorithm 4: DECOMPOSE-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'With_anisotropy' / 'Results_PCS.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'Without_anisotropy' / 'results_PCS.nii',\n",
    "    },\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), dpi=300)\n",
    "\n",
    "for idx in range(num_algorithms):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    algorithm_name = algorithm_names[idx]\n",
    "    \n",
    "    # Load the measured maps for the current algorithm\n",
    "    measured_with = nib.load(measured_maps[idx]['x_minus_with_anisotropy']).get_fdata() \n",
    "    measured_without = nib.load(measured_maps[idx]['x_minus_without_anisotropy']).get_fdata() \n",
    "    errors_with_regions = []\n",
    "    errors_without_regions = []\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # 1) Compute errors \n",
    "    # --------------------------------------------------\n",
    "    for region in region_labels:\n",
    "        region_mask = (segmentation2 == region)\n",
    "        \n",
    "        if region == 8:\n",
    "            continue\n",
    "        if np.any(region_mask):\n",
    "            # \"With Anisotropy\"\n",
    "            sim_val_with = np.mean(simulated_with[region_mask])\n",
    "           \n",
    "            if sim_val_with < 0:\n",
    "                sim_val_with *= -1\n",
    "            meas_val_with = np.mean(measured_with[region_mask])\n",
    "            if sim_val_with != 0:\n",
    "                error_with = ((meas_val_with - sim_val_with) / sim_val_with) ** 2 * 100\n",
    "            else:\n",
    "                error_with = np.nan\n",
    "\n",
    "            # \"Without Anisotropy\"\n",
    "            sim_val_without = np.mean(simulated_without[region_mask])\n",
    "            meas_val_without = np.mean(measured_without[region_mask])\n",
    "            if sim_val_without != 0:\n",
    "                error_without = ((meas_val_without - sim_val_without) / sim_val_without) ** 2 * 100\n",
    "            else:\n",
    "                error_without = np.nan\n",
    "\n",
    "            errors_with_regions.append(error_with)\n",
    "            errors_without_regions.append(error_without)\n",
    "    \n",
    "    # Convert to numpy arrays and remove NaNs\n",
    "    errors_with_regions = np.array(errors_with_regions)\n",
    "    errors_without_regions = np.array(errors_without_regions)\n",
    "    errors_with_regions = errors_with_regions[~np.isnan(errors_with_regions)]\n",
    "    errors_without_regions = errors_without_regions[~np.isnan(errors_without_regions)]\n",
    "    \n",
    "    # Prepare for KDE\n",
    "    x_vals = np.linspace(0, 70, 70)  \n",
    "    max_height = 0.4  \n",
    "    \n",
    "    # Plot KDE for \"With Anisotropy\"\n",
    "    if errors_with_regions.size > 1:\n",
    "        kde_with = gaussian_kde(errors_with_regions)\n",
    "        density_with = kde_with(x_vals)\n",
    "        scaling_with = max_height / np.max(density_with) if np.max(density_with) > 0 else 1\n",
    "        density_with_scaled = density_with * scaling_with\n",
    "        ax.fill_between(x_vals, 0, density_with_scaled, alpha=0.4, color='tab:blue')\n",
    "        ax.plot(x_vals, density_with_scaled, alpha=0.7, color='tab:blue')\n",
    "        mean_mspe_with = np.mean(errors_with_regions)\n",
    "    elif errors_with_regions.size == 1:\n",
    "        mean_mspe_with = errors_with_regions[0]\n",
    "        ax.plot([mean_mspe_with], [max_height/2], marker='o', color='tab:blue')\n",
    "    else:\n",
    "        mean_mspe_with = None\n",
    "\n",
    "    # Plot KDE for \"Without Anisotropy\"\n",
    "    if errors_without_regions.size > 1:\n",
    "        kde_without = gaussian_kde(errors_without_regions)\n",
    "        density_without = kde_without(x_vals)\n",
    "        scaling_without = max_height / np.max(density_without) if np.max(density_without) > 0 else 1\n",
    "        density_without_scaled = density_without * scaling_without\n",
    "        ax.fill_between(x_vals, 0, density_without_scaled, alpha=0.4, color='tab:orange')\n",
    "        ax.plot(x_vals, density_without_scaled, alpha=0.7, color='tab:orange')\n",
    "        mean_mspe_without = np.mean(errors_without_regions)\n",
    "    elif errors_without_regions.size == 1:\n",
    "        mean_mspe_without = errors_without_regions[0]\n",
    "        ax.plot([mean_mspe_without], [max_height/2], marker='o', color='tab:orange')\n",
    "    else:\n",
    "        mean_mspe_without = None\n",
    "    \n",
    "    # Show mean MSPE for with/without anisotropy\n",
    "    if mean_mspe_with is not None:\n",
    "        ax.text(0.95, 0.8, f\"Mean MSPE: {mean_mspe_with:.1f}%\", transform=ax.transAxes,\n",
    "                color='tab:blue', ha='right', va='center', fontsize=12)\n",
    "    if mean_mspe_without is not None:\n",
    "        ax.text(0.95, 0.7, f\"Mean MSPE: {mean_mspe_without:.1f}%\", transform=ax.transAxes,\n",
    "                color='tab:orange', ha='right', va='center', fontsize=12)\n",
    "\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='tab:blue', lw=2, label='With Anisotropy'),\n",
    "        Line2D([0], [0], color='tab:orange', lw=2, label='Without Anisotropy')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    ax.set_title(algorithm_name, fontsize=14)\n",
    "    ax.set_xlabel(\"MSPE of $\\\\chi^+$ (%)\", fontsize=12)\n",
    "    ax.set_ylabel(\"Density (a.u.)\", fontsize=12)\n",
    "    ax.set_ylim(0, max_height * 1.2)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# ---------------------------\n",
    "# Final figure adjustments\n",
    "# ---------------------------\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"Ï‡-separation\": (\n",
    "        base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiNegMap.nii',\n",
    "        base_dir / 'osfstorage' / '7T' / 'X-separation' / 'ChiNegMap.nii'\n",
    "    ),\n",
    "    \"R2*-QSM\": (\n",
    "       base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'With_anisotropy' / 'ChiNegMap.nii',\n",
    "        base_dir / 'osfstorage' / '7T' / 'R2star-QSM' / 'ChiNegMap.nii'\n",
    "    ),\n",
    "    \"APART-QSM\": (\n",
    "        base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'With_anisotropy' / 'X_dia_abs.nii',\n",
    "        base_dir / 'osfstorage' / '7T' / 'APART-QSM' / 'X_dia_abs.nii'\n",
    "    ),\n",
    "    \"DECOMPOSE-QSM\": (\n",
    "        base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'With_anisotropy' / 'Results_DCS_abs.nii',\n",
    "        base_dir / 'osfstorage' / '7T' / 'DECOMPOSE-QSM' /  'Results_DCS_abs.nii'\n",
    "    ),\n",
    "}\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# Load segmentation file\n",
    "#-----------------------------------------------------------------\n",
    "segmentation_file = base_dir / 'osfstorage' / 'Masks' / 'white_matter_mask.nii.gz'\n",
    "seg_nii  = nib.load(segmentation_file)\n",
    "seg_data = seg_nii.get_fdata()\n",
    "labels = range(1, 12)\n",
    "\n",
    "method_points = {}  \n",
    "\n",
    "all_mean_values = []\n",
    "all_difference_values = []\n",
    "\n",
    "for method_name, (nii_3T_path, nii_7T_path) in methods.items():\n",
    "    # --------------------\n",
    "    # Load the 3T and 7T\n",
    "    # --------------------\n",
    "    nii_3T = nib.load(nii_3T_path)\n",
    "    nii_7T = nib.load(nii_7T_path)\n",
    "    \n",
    "    data_3T = nii_3T.get_fdata()*-1\n",
    "    data_7T = nii_7T.get_fdata()*-1\n",
    "   \n",
    "    mean_values = np.zeros(len(labels))\n",
    "    diff_values = np.zeros(len(labels))\n",
    "    \n",
    "    for i, label_val in enumerate(labels):\n",
    "        # Mask for current region\n",
    "        mask = (seg_data == label_val)\n",
    "        \n",
    "        # Extract the region's data for 3T and 7T\n",
    "        region_3T = data_3T[mask]\n",
    "        region_7T = data_7T[mask]\n",
    "        \n",
    "        # Compute the mean within that region\n",
    "        mean_3T = np.mean(region_3T) if region_3T.size > 0 else np.nan\n",
    "        mean_7T = np.mean(region_7T) if region_7T.size > 0 else np.nan\n",
    "        \n",
    "        # Bland-Altman points\n",
    "        mean_values[i] = (mean_3T + mean_7T) / 2\n",
    "        diff_values[i] = (mean_3T - mean_7T)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    method_points[method_name] = (mean_values, diff_values)\n",
    "    \n",
    "    # Accumulate for global axis limits\n",
    "    all_mean_values.extend(mean_values)\n",
    "    all_difference_values.extend(diff_values)\n",
    "\n",
    "# Convert to NumPy for min/max\n",
    "all_mean_values = np.array(all_mean_values)\n",
    "all_difference_values = np.array(all_difference_values)\n",
    "\n",
    "# Determine global x-limits and y-limits\n",
    "x_min, x_max = np.min(all_mean_values), np.max(all_mean_values)\n",
    "x_margin = 0.1 * (x_max - x_min)  # 10% margin\n",
    "x_lim = (x_min - x_margin, x_max + x_margin)\n",
    "\n",
    "# Fixed y-limits as in your code\n",
    "y_lim = (-0.05, 0.05)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (method_name, (mean_values, difference_values)) in zip(axes, method_points.items()):\n",
    "    # Mean & LoA\n",
    "    mean_diff = np.mean(difference_values)\n",
    "    std_diff  = np.std(difference_values, ddof=1)\n",
    "    loa_upper = mean_diff + 1.96 * std_diff\n",
    "    loa_lower = mean_diff - 1.96 * std_diff\n",
    "\n",
    "    ax.scatter(mean_values, difference_values, marker=\"x\", s=50)\n",
    "    \n",
    "    # Plot lines\n",
    "    ax.axhline(mean_diff,  color=\"red\",   linestyle=\"--\")\n",
    "    ax.axhline(loa_upper, color=\"green\", linestyle=\"--\")\n",
    "    ax.axhline(loa_lower, color=\"green\", linestyle=\"--\")\n",
    "    \n",
    "    x_text = x_lim[0] + 0.05*(x_lim[1] - x_lim[0])\n",
    "    \n",
    "   \n",
    "    y_offset = 0.005 * (y_lim[1] - y_lim[0])  \n",
    "    \n",
    "    # (3) For each line, add text \"above\" the line value\n",
    "    def place_text_above_line(line_value, label_color):\n",
    "        y_text = line_value \n",
    "        # Clamp y_text so it doesn't exceed the top/bottom\n",
    "        y_text = max(min(y_text, y_lim[1] - 0.001), y_lim[0] + 0.0)\n",
    "        ax.text(x_text, y_text, f\"{line_value:.4f}\", color=label_color,\n",
    "                va=\"bottom\", ha=\"left\",)\n",
    "    \n",
    "    place_text_above_line(mean_diff,  \"red\")    # Mean difference\n",
    "    place_text_above_line(loa_upper, \"green\")  # +1.96 SD\n",
    "    place_text_above_line(loa_lower, \"green\")  # -1.96 SD\n",
    "\n",
    "    # Labels, limits, etc.\n",
    "    ax.set_xlabel(r\"Mean of $\\chi^{-}_{\\text{3 T}}$ and $\\chi^{-}_{\\text{7 T}} \\:(ppm)$\")\n",
    "    ax.set_ylabel(r\"Difference $\\chi^{-}_{\\text{3 T}} - \\chi^{-}_{\\text{7 T}} \\:(ppm)$\")\n",
    "    ax.set_title(method_name)\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
