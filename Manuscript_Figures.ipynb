{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import gaussian_kde \n",
    "from matplotlib.lines import Line2D    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the user to enter the full path to the data directory\n",
    "base_dir = Path(input(\"Please enter the full path to your data directory: \"))\n",
    "\n",
    "# Verify that the parent of the entered path exists\n",
    "if not base_dir.parent.exists():\n",
    "    raise FileNotFoundError(f\"The specified path {base_dir.parent} does not exist.\")\n",
    "else:\n",
    "    # Create the last folder if it doesn't exist\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Using data directory: {base_dir}\")\n",
    "!pip install osfclient\n",
    "# Clone the OSF project into the specified directory\n",
    "!osf -u USERNAME -p 9xwhz clone \"{base_dir}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of susceptibility anisotropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# Parameters and File Paths\n",
    "# ---------------------------\n",
    "num_algorithms = 4\n",
    "algorithm_names = [\n",
    "    '$\\\\chi$-separation', \n",
    "    'R2*-QSM', \n",
    "    'APART-QSM', \n",
    "    'DECOMPOSE-QSM'\n",
    "]\n",
    "\n",
    "# Load segmentation mask (assumed to contain region labels 1 to 11)\n",
    "segmentation2_path = base_dir / 'osfstorage' / 'Masks' / 'white_matter_mask.nii.gz'\n",
    "segmentation2 = nib.load(segmentation2_path).get_fdata()\n",
    "region_labels = list(range(1, 12))  # regions 1 to 11\n",
    "\n",
    "# Load simulated maps (common for all algorithms)\n",
    "simulated_with_path = base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_negative_with_anisotropy.nii.gz'\n",
    "simulated_without_path = base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_negative.nii.gz'\n",
    "simulated_with = nib.load(simulated_with_path).get_fdata()\n",
    "simulated_without = nib.load(simulated_without_path).get_fdata()\n",
    "\n",
    "# Define measured maps for each algorithm\n",
    "measured_maps = {\n",
    "    0: {  # Algorithm 1: χ-separation\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiNegMap.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'Without_anisotropy' / 'ChiNegMap.nii',\n",
    "    },\n",
    "    1: {  # Algorithm 2: R2*-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'With_anisotropy' / 'ChiNegMap.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'Without_anisotropy' / 'ChiNegMap.nii',\n",
    "    },\n",
    "    2: {  # Algorithm 3: APART-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'With_anisotropy' / 'X_dia_abs.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'Without_anisotropy' / 'X_dia_abs.nii',\n",
    "    },\n",
    "    3: {  # Algorithm 4: DECOMPOSE-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'With_anisotropy' / 'Results_DCS_abs.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'Without_anisotropy' / 'results_DCS_abs.nii',\n",
    "    },\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), dpi=300)\n",
    "t_test_results = {}\n",
    "for idx in range(num_algorithms):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    algorithm_name = algorithm_names[idx]\n",
    "    \n",
    "    measured_with = nib.load(measured_maps[idx]['x_minus_with_anisotropy']).get_fdata() * -1\n",
    "    measured_without = nib.load(measured_maps[idx]['x_minus_without_anisotropy']).get_fdata() * -1\n",
    "\n",
    "    errors_with_regions = []\n",
    "    errors_without_regions = []\n",
    "    \n",
    "    for region in region_labels:\n",
    "        region_mask = segmentation2 == region\n",
    "        if np.any(region_mask):\n",
    "            # For \"With Anisotropy\"\n",
    "            sim_val_with = np.mean(simulated_with[region_mask])\n",
    "            meas_val_with = np.mean(measured_with[region_mask])\n",
    "            if sim_val_with != 0:\n",
    "                error_with = ((meas_val_with - sim_val_with) / sim_val_with) ** 2 * 100\n",
    "            else:\n",
    "                error_with = np.nan\n",
    "            \n",
    "            # For \"Without Anisotropy\"\n",
    "            sim_val_without = np.mean(simulated_without[region_mask])\n",
    "            meas_val_without = np.mean(measured_without[region_mask])\n",
    "            if sim_val_without != 0:\n",
    "                error_without = ((meas_val_without - sim_val_without) / sim_val_without) ** 2 * 100\n",
    "            else:\n",
    "                error_without = np.nan\n",
    "            \n",
    "            errors_with_regions.append(error_with)\n",
    "            errors_without_regions.append(error_without)\n",
    "   \n",
    "    errors_with_regions = np.array(errors_with_regions)\n",
    "    errors_without_regions = np.array(errors_without_regions)\n",
    "    errors_with_regions = errors_with_regions[~np.isnan(errors_with_regions)]\n",
    "    errors_without_regions = errors_without_regions[~np.isnan(errors_without_regions)]\n",
    "\n",
    "    x_vals = np.linspace(0, 70, 200)  \n",
    "    max_height = 0.4  \n",
    "    \n",
    "    # Plot KDE for \"With Anisotropy\"\n",
    "    if errors_with_regions.size > 1:\n",
    "        kde_with = gaussian_kde(errors_with_regions)\n",
    "        density_with = kde_with(x_vals)\n",
    "        scaling_with = max_height / np.max(density_with) if np.max(density_with) > 0 else 1\n",
    "        density_with_scaled = density_with * scaling_with\n",
    "        ax.fill_between(x_vals, 0, density_with_scaled, color='tab:blue', alpha=0.4)\n",
    "        ax.plot(x_vals, density_with_scaled, color='tab:blue', alpha=0.7)\n",
    "        mean_mspe_with = np.mean(errors_with_regions)\n",
    "    elif errors_with_regions.size == 1:\n",
    "        mean_mspe_with = errors_with_regions[0]\n",
    "        ax.plot([mean_mspe_with], [max_height/2], marker='o', color='tab:blue')\n",
    "    else:\n",
    "        mean_mspe_with = None  # no data available\n",
    "\n",
    "    # Plot KDE for \"Without Anisotropy\"\n",
    "    if errors_without_regions.size > 1:\n",
    "        kde_without = gaussian_kde(errors_without_regions)\n",
    "        density_without = kde_without(x_vals)\n",
    "        scaling_without = max_height / np.max(density_without) if np.max(density_without) > 0 else 1\n",
    "        density_without_scaled = density_without * scaling_without\n",
    "        ax.fill_between(x_vals, 0, density_without_scaled, color='tab:orange', alpha=0.4)\n",
    "        ax.plot(x_vals, density_without_scaled, color='tab:orange', alpha=0.7)\n",
    "        mean_mspe_without = np.mean(errors_without_regions)\n",
    "    elif errors_without_regions.size == 1:\n",
    "        mean_mspe_without = errors_without_regions[0]\n",
    "        ax.plot([mean_mspe_without], [max_height/2], marker='o', color='tab:orange')\n",
    "    else:\n",
    "        mean_mspe_without = None\n",
    "\n",
    "    if mean_mspe_with is not None:\n",
    "        ax.text(0.95, 0.8, f\"Mean MSPE: {mean_mspe_with:.1f}%\", transform=ax.transAxes,\n",
    "                color='tab:blue', ha='right', va='center', fontsize=12)\n",
    "    if mean_mspe_without is not None:\n",
    "        ax.text(0.95, 0.7, f\"Mean MSPE: {mean_mspe_without:.1f}%\", transform=ax.transAxes,\n",
    "                color='tab:orange', ha='right', va='center', fontsize=12)\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # Create and add a legend for the subplot\n",
    "    # ------------------------------------------------\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='tab:blue', lw=2, label='With Anisotropy'),\n",
    "        Line2D([0], [0], color='tab:orange', lw=2, label='Without Anisotropy')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    # Set title and axis labels.\n",
    "    ax.set_title(algorithm_name, fontsize=14)\n",
    "    ax.set_xlabel(\"MSPE (%) of $\\\\chi^-$\", fontsize=12)\n",
    "    ax.set_ylabel(\"Density (a.u.)\", fontsize=12)\n",
    "    ax.set_xlim(0, 70)\n",
    "    ax.set_ylim(0, max_height * 1.2)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# ---------------------------\n",
    "# Final figure adjustments\n",
    "# ---------------------------\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define algorithms and SNR levels\n",
    "algorithms = ['$\\\\chi$-separation', 'R2*-QSM', 'APART-QSM', 'DECOMPOSE-QSM']\n",
    "snr_levels = [50, 100, 200, 300]\n",
    "\n",
    "# Initialize dictionaries to store errors\n",
    "x_positive_errors = {alg: [] for alg in algorithms}\n",
    "x_negative_errors = {alg: [] for alg in algorithms}\n",
    "\n",
    "\n",
    "def construct_path(*args):\n",
    "    return base_dir / 'osfstorage' / Path(*args)\n",
    "\n",
    "# Load the simulated maps\n",
    "simulated_positive_path = construct_path('Susceptibility_Separation_Results', 'Chi_positive.nii.gz')\n",
    "simulated_negative_path = construct_path('Susceptibility_Separation_Results', 'Chi_negative_with_anisotropy.nii.gz')\n",
    "simulated_positive = nib.load(simulated_positive_path).get_fdata()\n",
    "simulated_negative = nib.load(simulated_negative_path).get_fdata()\n",
    "\n",
    "# Load the segmentation masks\n",
    "segmentation_positive_path = construct_path('Masks', 'SegmentedModel.nii.gz')\n",
    "segmentation_negative_path = construct_path('Masks', 'white_matter_mask.nii.gz')\n",
    "segmentation_positive = nib.load(segmentation_positive_path).get_fdata()\n",
    "segmentation_negative = nib.load(segmentation_negative_path).get_fdata()\n",
    "\n",
    "# Specify the measured maps file paths individually\n",
    "measured_maps_positive = {\n",
    "    '$\\\\chi$-separation': {\n",
    "        300: construct_path('Noise', 'X-separation', 'SNR_300', 'ChiPosMap.nii.gz'),\n",
    "        200: construct_path('Noise', 'X-separation', 'SNR_200', 'ChiPosMap.nii.gz'),\n",
    "        100: construct_path('Noise', 'X-separation', 'SNR_100', 'ChiPosMap.nii.gz'),\n",
    "        50:  construct_path('Noise', 'X-separation', 'SNR_50', 'ChiPosMap.nii.gz'),\n",
    "    },\n",
    "    'R2*-QSM': {\n",
    "        300: construct_path('Noise', 'R2star-QSM', 'SNR_300', 'ChiPosMap.nii.gz'),\n",
    "        200: construct_path('Noise', 'R2star-QSM', 'SNR_200', 'ChiPosMap.nii.gz'),\n",
    "        100: construct_path('Noise', 'R2star-QSM', 'SNR_100', 'ChiPosMap.nii.gz'),\n",
    "        50:  construct_path('Noise', 'R2star-QSM', 'SNR_50', 'ChiPosMap.nii.gz'),\n",
    "    },\n",
    "    'APART-QSM': {\n",
    "        300: construct_path('Noise', 'APART-QSM', 'SNR_300', 'X_para.nii.gz'),\n",
    "        200: construct_path('Noise', 'APART-QSM', 'SNR_200', 'X_para.nii.gz'),\n",
    "        100: construct_path('Noise', 'APART-QSM', 'SNR_100', 'X_para.nii.gz'),\n",
    "        50:  construct_path('Noise', 'APART-QSM', 'SNR_50', 'X_para.nii.gz'),\n",
    "    },\n",
    "    'DECOMPOSE-QSM': {\n",
    "        300: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_300', 'results_PCS.nii.gz'),\n",
    "        200: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_200', 'results_PCS.nii.gz'),\n",
    "        100: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_100', 'results_PCS.nii.gz'),\n",
    "        50:  construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_50', 'results_PCS.nii.gz'),\n",
    "    },\n",
    "}\n",
    "\n",
    "measured_maps_negative = {\n",
    "    '$\\\\chi$-separation': {\n",
    "        300: construct_path('Noise', 'X-separation', 'SNR_300', 'ChiNegMap.nii.gz'),\n",
    "        200: construct_path('Noise', 'X-separation', 'SNR_200', 'ChiNegMap.nii.gz'),\n",
    "        100: construct_path('Noise', 'X-separation', 'SNR_100', 'ChiNegMap.nii.gz'),\n",
    "        50:  construct_path('Noise', 'X-separation', 'SNR_50', 'ChiNegMap.nii.gz'),\n",
    "    },\n",
    "    'R2*-QSM': {\n",
    "        300: construct_path('Noise', 'R2star-QSM', 'SNR_300', 'ChiNegMap.nii.gz'),\n",
    "        200: construct_path('Noise', 'R2star-QSM', 'SNR_200', 'ChiNegMap.nii.gz'),\n",
    "        100: construct_path('Noise', 'R2star-QSM', 'SNR_100', 'ChiNegMap.nii.gz'),\n",
    "        50:  construct_path('Noise', 'R2star-QSM', 'SNR_50', 'ChiNegMap.nii.gz'),\n",
    "    },\n",
    "    'APART-QSM': {\n",
    "        300: construct_path('Noise', 'APART-QSM', 'SNR_300', 'X_dia_abs.nii.gz'),\n",
    "        200: construct_path('Noise', 'APART-QSM', 'SNR_200', 'X_dia_abs.nii.gz'),\n",
    "        100: construct_path('Noise', 'APART-QSM', 'SNR_100', 'X_dia_abs.nii.gz'),\n",
    "        50:  construct_path('Noise', 'APART-QSM', 'SNR_50', 'X_dia_abs.nii.gz'),\n",
    "    },\n",
    "    'DECOMPOSE-QSM': {\n",
    "        300: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_300', 'results_DCS_abs.nii.gz'),\n",
    "        200: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_200', 'results_DCS_abs.nii.gz'),\n",
    "        100: construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_100', 'results_DCS_abs.nii.gz'),\n",
    "        50:  construct_path('Noise', 'DECOMPOSE-QSM', 'SNR_50', 'results_DCS_abs.nii.gz'),\n",
    "    },\n",
    "}\n",
    "\n",
    "# For each algorithm and SNR level, load the maps individually\n",
    "for alg in algorithms:\n",
    "    for snr in snr_levels:\n",
    "        # Get the file paths\n",
    "        measured_positive_path = measured_maps_positive[alg][snr]\n",
    "        measured_negative_path = measured_maps_negative[alg][snr]\n",
    "        \n",
    "        # Load the measured maps\n",
    "        measured_positive = nib.load(measured_positive_path).get_fdata()\n",
    "        measured_negative = nib.load(measured_negative_path).get_fdata()\n",
    "        \n",
    "        # Multiply measured negative map by -1\n",
    "        measured_negative = -1 * measured_negative\n",
    "        \n",
    "        # Positive regions \n",
    "        positive_errors = []\n",
    "        for region in range(1, 10):\n",
    "            # Create mask for this region\n",
    "            mask = (segmentation_positive == region)\n",
    "            \n",
    "            # Extract mean values\n",
    "            measured_mean = np.mean(measured_positive[mask])\n",
    "            simulated_mean = np.mean(simulated_positive[mask])\n",
    "            \n",
    "            # Compute error\n",
    "            error = ((measured_mean - simulated_mean) / simulated_mean) ** 2 * 100\n",
    "            positive_errors.append(error)\n",
    "        \n",
    "        # Compute average error over regions\n",
    "        avg_positive_error = np.mean(positive_errors)\n",
    "        x_positive_errors[alg].append(avg_positive_error)\n",
    "        \n",
    "        # Negative regions:\n",
    "        negative_errors = []\n",
    "        \n",
    "        # Regions 1 to 9 from segmentation_positive\n",
    "        for region in range(1, 10):\n",
    "            # Create mask for this region\n",
    "            mask = (segmentation_positive == region)\n",
    "            \n",
    "            # Extract mean values\n",
    "            measured_mean = np.mean(measured_negative[mask])\n",
    "            simulated_mean = np.mean(simulated_negative[mask])\n",
    "            \n",
    "            # Compute error\n",
    "            error = ((measured_mean - simulated_mean) / simulated_mean) ** 2 * 100\n",
    "            negative_errors.append(error)\n",
    "        \n",
    "        # Regions 1 to 10 from segmentation_negative\n",
    "        for region in range(1, 11):\n",
    "            # Create mask for this region\n",
    "            mask = (segmentation_negative == region)\n",
    "            \n",
    "            # Extract mean values\n",
    "            measured_mean = np.mean(measured_negative[mask])\n",
    "            simulated_mean = np.mean(simulated_negative[mask])\n",
    "            \n",
    "            # Compute error\n",
    "            error = ((measured_mean - simulated_mean) / simulated_mean) ** 2 * 100\n",
    "            negative_errors.append(error)\n",
    "        \n",
    "        # Compute average error over all 19 regions\n",
    "        avg_negative_error = np.mean(negative_errors)\n",
    "        x_negative_errors[alg].append(avg_negative_error)\n",
    "\n",
    "# Define hatch patterns for distinction\n",
    "hatch_patterns = ['x', 'o', '*', '+']  \n",
    "\n",
    "# Define color mapping based on SNR\n",
    "snr_colors = {\n",
    "    50:  '#66c2a5', \n",
    "    100: '#8da0cb', \n",
    "    200: '#fc8d62', \n",
    "    300: '#e78ac3',  \n",
    "}\n",
    "\n",
    "# Bar width and x positions\n",
    "bar_width = 0.2\n",
    "snr_index = np.arange(len(snr_levels))\n",
    "\n",
    "# Figure setup\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "tick_font_size = 14\n",
    "legend_font_size = 14\n",
    "\n",
    "# --- Plot X-positive ---\n",
    "for i, (alg, hatch) in enumerate(zip(algorithms, hatch_patterns)):\n",
    "    # For legend clarity: we only label the algorithm on the first SNR iteration\n",
    "    for j, snr in enumerate(snr_levels):\n",
    "        # x-coordinate for this bar\n",
    "        x_coord = snr_index[j] + i * bar_width\n",
    "        # The MSPE value for this algorithm at the j-th SNR\n",
    "        y_value = x_positive_errors[alg][j]\n",
    "       \n",
    "        # Plot a single bar\n",
    "        ax1.bar(\n",
    "            x_coord,\n",
    "            y_value,\n",
    "            bar_width,\n",
    "            label=alg if j == 0 else None,  \n",
    "            hatch=hatch,\n",
    "            edgecolor='black',\n",
    "            color=snr_colors[snr],         \n",
    "            )\n",
    "\n",
    "ax1.set_xlabel('SNR', fontsize=tick_font_size)\n",
    "ax1.set_ylabel('MSPE of $\\\\chi^+$', fontsize=tick_font_size)\n",
    "\n",
    "ax1.set_xticks(snr_index + bar_width * 1.5)\n",
    "ax1.set_xticklabels(snr_levels, fontsize=tick_font_size)\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# --- Plot X-negative ---\n",
    "for i, (alg, hatch) in enumerate(zip(algorithms, hatch_patterns)):\n",
    "    for j, snr in enumerate(snr_levels):\n",
    "        x_coord = snr_index[j] + i * bar_width\n",
    "        y_value = x_negative_errors[alg][j]\n",
    "        \n",
    "        ax2.bar(\n",
    "            x_coord,\n",
    "            y_value,\n",
    "            bar_width,\n",
    "            label=alg if j == 0 else None,\n",
    "            hatch=hatch,\n",
    "            edgecolor='black',\n",
    "            color=snr_colors[snr],\n",
    "        )\n",
    "\n",
    "ax2.set_xlabel('SNR', fontsize=tick_font_size)\n",
    "ax2.set_ylabel('MSPE of $\\\\chi^-$', fontsize=tick_font_size)\n",
    "\n",
    "ax2.set_xticks(snr_index + bar_width * 1.5)\n",
    "ax2.set_xticklabels(snr_levels, fontsize=tick_font_size)\n",
    "ax2.legend(fontsize=legend_font_size, facecolor='white', framealpha=1)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Adjust tick sizes\n",
    "ax1.tick_params(axis='both', which='major', labelsize=tick_font_size)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=tick_font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of noise on susceptibility anisotorpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the algorithms and SNR levels\n",
    "algorithms = ['x-separation', 'R2*-QSM', 'APART-QSM', 'DECOMPOSE-QSM']\n",
    "snr_levels = ['SNR 300', 'SNR 200', 'SNR 100', 'SNR 50']\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store the full paths for measured images\n",
    "measured_image_paths = {\n",
    "    'x-separation': {\n",
    "        'SNR 300': base_dir / 'osfstorage' / 'Noise' / 'X-separation' / 'SNR_300' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 200': base_dir / 'osfstorage' / 'Noise' / 'X-separation' / 'SNR_200' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 100': base_dir / 'osfstorage' / 'Noise' / 'X-separation' / 'SNR_100' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 50': base_dir / 'osfstorage' / 'Noise' / 'X-separation' / 'SNR_50' / 'ChiNegMap.nii.gz',\n",
    "    },\n",
    "    'R2*-QSM': {\n",
    "        'SNR 300': base_dir / 'osfstorage' / 'Noise' / 'R2star-QSM' / 'SNR_300' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 200': base_dir / 'osfstorage' / 'Noise' / 'R2star-QSM' / 'SNR_200' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 100': base_dir / 'osfstorage' / 'Noise' / 'R2star-QSM' / 'SNR_100' / 'ChiNegMap.nii.gz',\n",
    "        'SNR 50': base_dir / 'osfstorage' / 'Noise' / 'R2star-QSM' / 'SNR_50' / 'ChiNegMap.nii.gz',\n",
    "    },\n",
    "    'APART-QSM': {\n",
    "        'SNR 300': base_dir / 'osfstorage' / 'Noise' / 'APART-QSM' / 'SNR_300' / 'X_dia_abs.nii.gz',\n",
    "        'SNR 200': base_dir / 'osfstorage' / 'Noise' / 'APART-QSM' / 'SNR_200' / 'X_dia_abs.nii.gz',\n",
    "        'SNR 100': base_dir / 'osfstorage' / 'Noise' / 'APART-QSM' / 'SNR_100' / 'X_dia_abs.nii.gz',\n",
    "        'SNR 50': base_dir / 'osfstorage' / 'Noise' / 'APART-QSM' / 'SNR_50' / 'X_dia_abs.nii.gz',\n",
    "    },\n",
    "    'DECOMPOSE-QSM': {\n",
    "        'SNR 300': base_dir / 'osfstorage' / 'Noise' / 'DECOMPOSE-QSM' / 'SNR_300' / 'results_DCS_abs.nii.gz',\n",
    "        'SNR 200': base_dir / 'osfstorage' / 'Noise' / 'DECOMPOSE-QSM' / 'SNR_200' / 'results_DCS_abs.nii.gz',\n",
    "        'SNR 100': base_dir / 'osfstorage' / 'Noise' / 'DECOMPOSE-QSM' / 'SNR_100' / 'results_DCS_abs.nii.gz',\n",
    "        'SNR 50': base_dir / 'osfstorage' / 'Noise' / 'DECOMPOSE-QSM' / 'SNR_50' / 'results_DCS_abs.nii.gz',\n",
    "    },\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) LOAD NIFTI DATA\n",
    "# ----------------------------\n",
    "\n",
    "# Load simulated (ground truth) chi, theta, and segmentation images\n",
    "simulated_nii = nib.load(base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_negative_with_anisotropy.nii.gz')\n",
    "simulated_img_with_anisotropy = simulated_nii.get_fdata()\n",
    "\n",
    "theta_nii = nib.load(base_dir / 'osfstorage' / 'Noise' / 'theta.nii.gz')\n",
    "theta_img = theta_nii.get_fdata()\n",
    "theta_img[np.isnan(theta_img)] = 0\n",
    "\n",
    "segmentation_nii = nib.load(base_dir / 'osfstorage' / 'Masks' / 'WM_fibers_seg.nii.gz')\n",
    "segmentation_img = segmentation_nii.get_fdata()\n",
    "\n",
    "theta_shape = theta_nii.shape\n",
    "theta_affine = theta_nii.affine\n",
    "\n",
    "# Load measured images for each algorithm and SNR\n",
    "measured_images = {}\n",
    "for algorithm in algorithms:\n",
    "    measured_images[algorithm] = {}\n",
    "    for snr in snr_levels:\n",
    "        path = measured_image_paths[algorithm][snr]\n",
    "        measured_images[algorithm][snr] = nib.load(path).get_fdata()\n",
    "\n",
    "# ----------------------------\n",
    "# 3) GATHER VALID VOXELS & COMPUTE ERRORS\n",
    "# ----------------------------\n",
    "\n",
    "all_valid_coords = []  \n",
    "all_theta_values = []\n",
    "all_sim_values = []\n",
    "\n",
    "errors = {\n",
    "    algorithm: {\n",
    "        snr: [] for snr in snr_levels\n",
    "    }\n",
    "    for algorithm in algorithms\n",
    "}\n",
    "\n",
    "# Loop over the segmentation regions \n",
    "for region in range(1, 28):\n",
    "    # Region mask\n",
    "    region_mask = (segmentation_img == region)\n",
    "    region_valid_mask = region_mask & (theta_img != 0)\n",
    "    \n",
    "    # Get the 3D coordinates of those valid voxels\n",
    "    valid_coords = np.argwhere(region_valid_mask)\n",
    "    if valid_coords.size == 0:\n",
    "        continue  \n",
    "\n",
    "    # Extract the actual voxel values\n",
    "    region_theta_vals = theta_img[region_valid_mask]\n",
    "    region_sim_vals = simulated_img_with_anisotropy[region_valid_mask] * -1\n",
    "\n",
    "    # Append these to our global lists\n",
    "    all_valid_coords.append(valid_coords)\n",
    "    all_theta_values.append(region_theta_vals)\n",
    "    all_sim_values.append(region_sim_vals)\n",
    "\n",
    "    # For each algorithm & SNR, calculate MSPE in this region and append\n",
    "    for algorithm in algorithms:\n",
    "        for snr in snr_levels:\n",
    "            measured_vals = measured_images[algorithm][snr][region_valid_mask]\n",
    "            epsilon = 1e-10  \n",
    "            relative_squared_error = np.sqrt(\n",
    "            np.square(region_sim_vals - measured_vals) /\n",
    "            (np.square(region_sim_vals) + epsilon)\n",
    "            ) * 100\n",
    "            errors[algorithm][snr].append(relative_squared_error)\n",
    "\n",
    "all_valid_coords = np.concatenate(all_valid_coords, axis=0)\n",
    "all_theta_values = np.concatenate(all_theta_values, axis=0)\n",
    "all_sim_values = np.concatenate(all_sim_values, axis=0)\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    for snr in snr_levels:\n",
    "        errors[algorithm][snr] = np.concatenate(errors[algorithm][snr], axis=0)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) BIN THE THETA VALUES \n",
    "# ----------------------------\n",
    "\n",
    "bins = np.arange(0, 100, 10)  \n",
    "\n",
    "bin_indices = np.digitize(all_theta_values, bins)  \n",
    "num_bins = len(bins) - 1  \n",
    "\n",
    "# Calculate the mean bin angle\n",
    "bin_means_theta = []\n",
    "for b in range(1, len(bins)):\n",
    "    mask_b = (bin_indices == b)\n",
    "    if np.any(mask_b):\n",
    "        bin_means_theta.append(np.mean(all_theta_values[mask_b]))\n",
    "bin_means_theta = np.array(bin_means_theta)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) CALCULATE BIN MEANS OF MSPE FOR EACH ALGORITHM AND SNR\n",
    "# ----------------------------\n",
    "\n",
    "bin_means = {\n",
    "    algorithm: {\n",
    "        snr: [] for snr in snr_levels\n",
    "    } for algorithm in algorithms\n",
    "}\n",
    "\n",
    "for b in range(1, len(bins)):\n",
    "    mask_b = (bin_indices == b)\n",
    "    if np.any(mask_b):\n",
    "        for algorithm in algorithms:\n",
    "            for snr in snr_levels:\n",
    "                mspe_values_bin = errors[algorithm][snr][mask_b]\n",
    "                bin_mean_error = np.mean(mspe_values_bin)\n",
    "                bin_means[algorithm][snr].append(bin_mean_error)\n",
    "    else:\n",
    "        \n",
    "        for algorithm in algorithms:\n",
    "            for snr in snr_levels:\n",
    "                bin_means[algorithm][snr].append(np.nan)\n",
    "\n",
    "# Convert bin means to numpy arrays\n",
    "for algorithm in algorithms:\n",
    "    for snr in snr_levels:\n",
    "        bin_means[algorithm][snr] = np.array(bin_means[algorithm][snr])\n",
    "\n",
    "# ----------------------------\n",
    "# 6) SAVE A SINGLE 3D MASK WITH BIN LABELS\n",
    "# ----------------------------\n",
    "\n",
    "all_bins_3d = np.zeros(theta_shape, dtype=np.uint8)\n",
    "\n",
    "for b in range(1, len(bins)):\n",
    "    # Voxels in bin b\n",
    "    mask_b = (bin_indices == b)\n",
    "    \n",
    "    # Coordinates of voxels in bin b\n",
    "    bin_coords = all_valid_coords[mask_b]\n",
    "    all_bins_3d[bin_coords[:, 0], bin_coords[:, 1], bin_coords[:, 2]] = b\n",
    "\n",
    "# ----------------------------\n",
    "# 7) PLOT THE RESULTS\n",
    "# ----------------------------\n",
    "\n",
    "markers = {\n",
    "    'SNR 300': ('#e78ac3', 'o'),\n",
    "    'SNR 200': ('#fc8d62', 'o'),\n",
    "    'SNR 100': ('#8da0cb', 'o'),\n",
    "    'SNR 50': ('#66c2a5', 'o')\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "algorithm_subplot_indices = {\n",
    "    'x-separation': (0, 0),\n",
    "    'R2*-QSM': (0, 1),\n",
    "    'APART-QSM': (1, 0),\n",
    "    'DECOMPOSE-QSM': (1, 1)\n",
    "}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    ax = axs[algorithm_subplot_indices[algorithm]]\n",
    "    \n",
    "    # Dictionary to store percentage changes for each SNR\n",
    "    percentage_changes = {}\n",
    "    \n",
    "    for snr in snr_levels:\n",
    "        color, marker = markers[snr]\n",
    "        \n",
    "        # x-values = bin_means_theta\n",
    "        x_vals = bin_means_theta\n",
    "        # y-values = bin_means[algorithm][snr]\n",
    "        y_vals = bin_means[algorithm][snr]\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax.scatter(\n",
    "            x_vals,\n",
    "            y_vals,\n",
    "            color=color,\n",
    "            marker=marker,\n",
    "            label=snr\n",
    "        )\n",
    "        \n",
    "        # 1) Sort the points by x so we can connect them in ascending order\n",
    "        sort_idx = np.argsort(x_vals)\n",
    "        x_sorted = x_vals[sort_idx]\n",
    "        y_sorted = y_vals[sort_idx]\n",
    "       \n",
    "        # Calculate percentage change (max vs. min) for this SNR\n",
    "        valid_mspe = y_vals[~np.isnan(y_vals)]\n",
    "        if len(valid_mspe) > 0:\n",
    "            max_mspe = np.max(valid_mspe)\n",
    "            min_mspe = np.min(valid_mspe)\n",
    "            if max_mspe != 0:\n",
    "                percentage_change = (max_mspe - min_mspe) / max_mspe * 100\n",
    "            else:\n",
    "                percentage_change = 0\n",
    "        else:\n",
    "            percentage_change = 0\n",
    "        \n",
    "        percentage_changes[snr] = percentage_change\n",
    "\n",
    "    # Build the \"MEV=\" Variation text with Matplotlib colors\n",
    "    x_position = 0.47\n",
    "    y_position = 0.05\n",
    "\n",
    "    ax.text(\n",
    "        x_position, y_position,\n",
    "        \"MEV=\",\n",
    "        transform=ax.transAxes, fontsize=12, color='black', ha='left', va='top'\n",
    "    )\n",
    "    x_position += 0.1\n",
    "\n",
    "    text_colors = ['#e78ac3', '#fc8d62', '#8da0cb', '#66c2a5']\n",
    "    for idx, snr in enumerate(snr_levels):\n",
    "        color_ = text_colors[idx]\n",
    "        ax.text(\n",
    "            x_position, y_position,\n",
    "            f\"{percentage_changes[snr]:.1f}%\",\n",
    "            transform=ax.transAxes, fontsize=12, color=color_, ha='left', va='top'\n",
    "        )\n",
    "        x_position += 0.1\n",
    "\n",
    "    # Set titles and labels\n",
    "    if algorithm == 'x-separation':\n",
    "        ax.set_title(r\"$\\chi$-separation\")\n",
    "    else:\n",
    "        ax.set_title(algorithm)\n",
    "\n",
    "    ax.set_xlabel('Angle of Orientation (degrees)', fontsize=16)\n",
    "    ax.set_ylabel('MSPE of $\\\\chi^-$ (%)', fontsize=16)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 130)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between simulated vs in-vivo susceptibility maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regions of interest\n",
    "regions_of_interest = [1, 2, 3, 7, 8, 9]\n",
    "\n",
    "# Function to extract mean values per region\n",
    "def extract_mean_per_region(data_map, segmentation_map, regions):\n",
    "    means = []\n",
    "    for region in regions:\n",
    "        region_mask = segmentation_map == region\n",
    "        if np.any(region_mask):\n",
    "            mean_value = np.mean(data_map[region_mask])\n",
    "            means.append(mean_value)\n",
    "        else:\n",
    "            means.append(np.nan)  \n",
    "    return means\n",
    "\n",
    "# Load segmentation maps\n",
    "segmentation_in_vivo = nib.load(base_dir / 'osfstorage' / 'Masks' / 'in_vivo_segmentation.nii.gz').get_fdata()\n",
    "segmentation_simulated = nib.load(base_dir / 'osfstorage' / 'Masks' / 'SegmentedModel.nii.gz').get_fdata()\n",
    "\n",
    "# Initialize dictionaries to store mean values\n",
    "chi_positive_in_vivo_means = {}\n",
    "chi_positive_simulated_means = {}\n",
    "chi_negative_in_vivo_means = {}\n",
    "chi_negative_simulated_means = {}\n",
    "\n",
    "# Load data for chi-positive \n",
    "\n",
    "chi_positive_in_vivo_files = {\n",
    "    'chi-separation': base_dir / 'osfstorage' / 'In-vivo' / 'X-separation' / 'ChiPosMap.nii',\n",
    "    'R2*-QSM': base_dir / 'osfstorage' / 'In-vivo' / 'R2star-QSM' / 'ChiPosMap.nii',\n",
    "    'APART-QSM': base_dir / 'osfstorage' / 'In-vivo' / 'APART-QSM' / 'X_para.nii',\n",
    "    'DECOMPOSE-QSM': base_dir / 'osfstorage' / 'In-vivo' / 'DECOMPOSE-QSM' / 'results_PCS.nii'\n",
    "}\n",
    "\n",
    "chi_positive_simulated_files = {\n",
    "    'chi-separation': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiPosMap.nii',\n",
    "    'R2*-QSM': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'With_anisotropy' / 'ChiPosMap.nii',\n",
    "    'APART-QSM': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'With_anisotropy' / 'X_para.nii',\n",
    "    'DECOMPOSE-QSM': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'With_anisotropy' / 'Results_PCS.nii'\n",
    "}\n",
    "\n",
    "# Process chi-positive \n",
    "for algo in chi_positive_in_vivo_files.keys():\n",
    "    in_vivo_map = nib.load(chi_positive_in_vivo_files[algo]).get_fdata()\n",
    "    simulated_map = nib.load(chi_positive_simulated_files[algo]).get_fdata()\n",
    "\n",
    "    in_vivo_means = extract_mean_per_region(in_vivo_map, segmentation_in_vivo, regions_of_interest)\n",
    "    simulated_means = extract_mean_per_region(simulated_map, segmentation_simulated, regions_of_interest)\n",
    "\n",
    "    chi_positive_in_vivo_means[algo] = in_vivo_means\n",
    "    chi_positive_simulated_means[algo] = simulated_means\n",
    "\n",
    "# Load data for chi-negative \n",
    "\n",
    "chi_negative_in_vivo_files = {\n",
    "    'chi-separation': base_dir / 'osfstorage' / 'In-vivo' / 'X-separation' / 'ChiNegMap.nii',\n",
    "    'R2*-QSM': base_dir / 'osfstorage' / 'In-vivo' / 'R2star-QSM' / 'ChiNegMap.nii',\n",
    "    'APART-QSM': base_dir / 'osfstorage' / 'In-vivo' / 'APART-QSM' / 'X_dia_abs.nii',\n",
    "    'DECOMPOSE-QSM': base_dir / 'osfstorage' / 'In-vivo' / 'DECOMPOSE-QSM' / 'results_DCS_abs.nii'\n",
    "}\n",
    "\n",
    "chi_negative_simulated_files = {\n",
    "    'chi-separation': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiNegMap.nii',\n",
    "    'R2*-QSM': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'With_anisotropy' / 'ChiNegMap.nii',\n",
    "    'APART-QSM': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'With_anisotropy' / 'X_dia_abs.nii',\n",
    "    'DECOMPOSE-QSM': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'With_anisotropy' / 'Results_DCS_abs.nii'\n",
    "}\n",
    "\n",
    "# Process chi-negative data\n",
    "for algo in chi_negative_in_vivo_files.keys():\n",
    "    in_vivo_map = nib.load(chi_negative_in_vivo_files[algo]).get_fdata()\n",
    "    in_vivo_map *= -1  \n",
    "    simulated_map = nib.load(chi_negative_simulated_files[algo]).get_fdata()\n",
    "    simulated_map *= -1  \n",
    "\n",
    "    in_vivo_means = extract_mean_per_region(in_vivo_map, segmentation_in_vivo, regions_of_interest)\n",
    "    simulated_means = extract_mean_per_region(simulated_map, segmentation_simulated, regions_of_interest)\n",
    "\n",
    "    chi_negative_in_vivo_means[algo] = in_vivo_means\n",
    "    chi_negative_simulated_means[algo] = simulated_means\n",
    "\n",
    "display_names = {\n",
    "    'chi-separation': r'$\\chi$-separation',\n",
    "    'R2*-QSM': 'R2*-QSM',\n",
    "    'APART-QSM': 'APART-QSM',\n",
    "    'DECOMPOSE-QSM': 'DECOMPOSE-QSM'\n",
    "}\n",
    "\n",
    "algorithms = list(chi_positive_in_vivo_files.keys())\n",
    "\n",
    "def plot_data(in_vivo_means_dict, simulated_means_dict, chi_type, ax):\n",
    "    marker_styles = ['x', 'o', '*', '+']  \n",
    "\n",
    "    for idx, algo in enumerate(algorithms):\n",
    "\n",
    "        x = np.array(in_vivo_means_dict[algo])\n",
    "        y = np.array(simulated_means_dict[algo])\n",
    "        mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "        x = x[mask]\n",
    "        y = y[mask]\n",
    "\n",
    "        if len(x) > 1:\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "            r_label = f\"(R²={r_value:.2f})\"\n",
    "            sorted_indices = np.argsort(x)\n",
    "            x_sorted = x[sorted_indices]\n",
    "            y_sorted = intercept + slope * x_sorted\n",
    "            ax.plot(x_sorted, y_sorted, color='black', linestyle='--', label=None)\n",
    "        else:\n",
    "            r_label = \"(R²=NaN)\"\n",
    "\n",
    "     \n",
    "        label = f\"{display_names[algo]} {r_label} \"\n",
    "\n",
    "       \n",
    "        marker = marker_styles[idx]\n",
    "        if marker == 'x':\n",
    "           \n",
    "            ax.scatter(x, y, marker=marker, s=80, color='black',\n",
    "                       linewidth=1.5, label=label)\n",
    "        elif marker == 'o':\n",
    "            \n",
    "            ax.scatter(x, y, marker=marker, s=80,\n",
    "                       edgecolors='black', facecolors='none',\n",
    "                       linewidth=1.5, label=label)\n",
    "        else:\n",
    "            \n",
    "            ax.scatter(x, y, marker=marker, s=80,\n",
    "                       color='black', linewidth=1.5, label=label)\n",
    "\n",
    "    # Adjust axis limits so the diagonal line covers all points\n",
    "    x_limits = ax.get_xlim()\n",
    "    y_limits = ax.get_ylim()\n",
    "    min_val = min(x_limits[0], y_limits[0])\n",
    "    max_val = max(x_limits[1], y_limits[1])\n",
    "    ax.set_xlim([min_val, max_val])\n",
    "    ax.set_ylim([min_val, max_val])\n",
    "\n",
    "    # Draw diagonal line in grey\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], '-',\n",
    "            color='grey',label='y = x', alpha=0.3)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel(f'Measured {chi_type} in-vivo (ppm)', fontsize=18)\n",
    "    ax.set_ylabel(f'Simulated {chi_type} (ppm)', fontsize=18)\n",
    "    ax.legend(loc='upper left', fontsize=14)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Adjust tick label size\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Plot chi-positive data\n",
    "plot_data(chi_positive_in_vivo_means, chi_positive_simulated_means,r'$\\chi^+$' , axes[0])\n",
    "\n",
    "# Plot chi-negative data\n",
    "plot_data(chi_negative_in_vivo_means, chi_negative_simulated_means,r'$\\chi^-$',  axes[1])\n",
    "\n",
    "# Adjust tick label size for both axes\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between simulated vs in-vivo field maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "simulated_map_path = base_dir / \"osfstorage/LocalField/Simulated_Field.nii.gz\"\n",
    "in_vivo_map_path = base_dir / \"osfstorage/LocalField/In_vivo_Field.nii.gz\"\n",
    "segmentation_map_path = base_dir / \"osfstorage/Masks/white_matter_mask.nii.gz\"\n",
    "\n",
    "# Load the NIfTI files \n",
    "simulated_map_nii = nib.load(simulated_map_path)\n",
    "in_vivo_map_nii = nib.load(in_vivo_map_path)\n",
    "segmentation_map_nii = nib.load(segmentation_map_path)\n",
    "\n",
    "# Extract the data arrays\n",
    "simulated_map = simulated_map_nii.get_fdata()\n",
    "in_vivo_map = in_vivo_map_nii.get_fdata()\n",
    "segmentation_map = segmentation_map_nii.get_fdata()\n",
    "\n",
    "# Extract values for scatter plot \n",
    "simulated_values = []\n",
    "in_vivo_values = []\n",
    "\n",
    "for region in range(1, 11):\n",
    "    region_mask = segmentation_map == region\n",
    "    simulated_region_values = simulated_map[region_mask]\n",
    "    in_vivo_region_values = in_vivo_map[region_mask]\n",
    "\n",
    "    # Take the mean value for each region\n",
    "    simulated_values.append(np.mean(simulated_region_values))\n",
    "    in_vivo_values.append(np.mean(in_vivo_region_values))\n",
    "\n",
    "# Convert lists to numpy arrays for plotting\n",
    "simulated_values = np.array(simulated_values)\n",
    "in_vivo_values = np.array(in_vivo_values)\n",
    "\n",
    "# Scatter plot with linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(in_vivo_values, simulated_values)\n",
    "regression_line = slope * in_vivo_values + intercept\n",
    "\n",
    "# Create the scatter plot\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Sort the x-values (in-vivo local field values) and calculate corresponding y-values\n",
    "sorted_indices = np.argsort(in_vivo_values)\n",
    "sorted_in_vivo_values = in_vivo_values[sorted_indices]\n",
    "sorted_regression_line = slope * sorted_in_vivo_values + intercept\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(in_vivo_values, simulated_values, color='black', zorder=2)\n",
    "\n",
    "# Plot the regression line with sorted values\n",
    "ax.plot(sorted_in_vivo_values, sorted_regression_line, linestyle='--', color='black', linewidth=1.2, zorder=1)\n",
    "\n",
    "# Add labels, grid, and R² text\n",
    "ax.set_xlabel('In-vivo local field (Hz)', fontsize=10)\n",
    "ax.set_ylabel('Simulated local field (Hz)', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.text(0.05, 0.95, f'$R^2 = {r_value:.2f}$\\nSlope = {slope:.1f}', ha='left', va='top', transform=ax.transAxes, fontsize=9)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between simulated vs in-vivo T2 maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File paths for NIfTI files\n",
    "in_vivo_t2_path = base_dir / \"osfstorage/T2/T2_in_vivo.nii.gz\"\n",
    "in_vivo_segmentation_path = base_dir / \"osfstorage/Masks/in_vivo_segmentation.nii.gz\"\n",
    "simulated_t2_path = base_dir / \"osfstorage/T2/T2_simulated_resampled.nii.gz\"\n",
    "simulated_segmentation_path = base_dir / \"osfstorage/Masks/SegmentedModel_resampled.nii.gz\"\n",
    "\n",
    "# Load NIfTI files\n",
    "in_vivo_t2_map = nib.load(in_vivo_t2_path).get_fdata()\n",
    "in_vivo_segmentation = nib.load(in_vivo_segmentation_path).get_fdata()\n",
    "simulated_t2_map = nib.load(simulated_t2_path).get_fdata()\n",
    "simulated_segmentation = nib.load(simulated_segmentation_path).get_fdata()\n",
    "\n",
    "# Replace NaN and Inf values with 0 in the T2 maps\n",
    "in_vivo_t2_map = np.nan_to_num(in_vivo_t2_map, nan=0, posinf=0, neginf=0)\n",
    "simulated_t2_map = np.nan_to_num(simulated_t2_map, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# Initialize lists for valid values\n",
    "T2_in_vivo = []\n",
    "T2_simulated = []\n",
    "\n",
    "# Extract in-vivo T2 values \n",
    "for region in list(range(1, 4)) + list(range(7, 10)):  \n",
    "    in_vivo_mask = in_vivo_segmentation == region\n",
    "    if np.any(in_vivo_mask):  \n",
    "        in_vivo_mean = np.mean(in_vivo_t2_map[in_vivo_mask])\n",
    "        T2_in_vivo.append(in_vivo_mean)\n",
    "\n",
    "# Extract simulated T2 values \n",
    "for region in list(range(1, 4)) + list(range(7, 10)):  \n",
    "    simulated_mask = simulated_segmentation == region\n",
    "    if np.any(simulated_mask):  \n",
    "        simulated_mean = np.mean(simulated_t2_map[simulated_mask])\n",
    "        T2_simulated.append(simulated_mean)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "T2_in_vivo = np.array(T2_in_vivo)\n",
    "T2_simulated = np.array(T2_simulated)\n",
    "\n",
    "# Reshape data for linear regression\n",
    "T2_in_vivo_reshaped = T2_in_vivo.reshape(-1, 1)\n",
    "T2_simulated_reshaped = T2_simulated.reshape(-1, 1)\n",
    "\n",
    "# Perform linear regression\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(T2_in_vivo_reshaped, T2_simulated_reshaped)\n",
    "\n",
    "# Regression line parameters\n",
    "slope = reg_model.coef_[0][0]\n",
    "intercept = reg_model.intercept_[0]\n",
    "\n",
    "# Generate regression line values\n",
    "x_fit = np.linspace(min(T2_in_vivo), max(T2_in_vivo), 100)\n",
    "y_fit = slope * x_fit + intercept\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(T2_in_vivo, T2_simulated, color='black', label='Data Points')  \n",
    "plt.plot(x_fit, y_fit, '--', color='black', label='Regression Line') \n",
    "plt.xlabel(r'$T_2^{\\mathrm{in-vivo}}$ (ms)', fontsize=16)\n",
    "plt.ylabel(r'$T_2^{\\mathrm{simulated}}$ (ms)', fontsize=16)\n",
    "\n",
    "# Add correlation and slope text with larger font\n",
    "correlation = np.corrcoef(T2_in_vivo, T2_simulated)[0, 1]\n",
    "plt.text(45, 120, f'Correlation: {correlation:.2f}\\nSlope: {slope:.2f}', fontsize=16)\n",
    "\n",
    "# Add grid and legend\n",
    "plt.grid(visible=True)\n",
    "\n",
    "\n",
    "# Increase tick label font size\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplimantary Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Parameters and File Paths\n",
    "# ---------------------------\n",
    "num_algorithms = 4\n",
    "algorithm_names = [\n",
    "    '$\\\\chi$-separation', \n",
    "    'R2*-QSM', \n",
    "    'APART-QSM', \n",
    "    'DECOMPOSE-QSM'\n",
    "]\n",
    "\n",
    "# Load segmentation mask (assumed to contain region labels 1 to 11)\n",
    "segmentation2_path = base_dir / 'osfstorage' / 'Masks' / 'SegmentedModel.nii.gz'\n",
    "segmentation2 = nib.load(segmentation2_path).get_fdata()\n",
    "region_labels = list(range(1, 10)) \n",
    "\n",
    "# Load simulated maps (common for all algorithms)\n",
    "simulated_with_path = base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_positive.nii.gz'\n",
    "simulated_without_path = base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'Chi_positive.nii.gz'\n",
    "simulated_with = nib.load(simulated_with_path).get_fdata()\n",
    "simulated_without = nib.load(simulated_without_path).get_fdata()\n",
    "\n",
    "# Define measured maps for each algorithm\n",
    "measured_maps = {\n",
    "    0: {  # Algorithm 1: χ-separation\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiPosMap.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'Without_anisotropy' / 'ChiPosMap.nii',\n",
    "    },\n",
    "    1: {  # Algorithm 2: R2*-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'With_anisotropy' / 'ChiPosMap.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'Without_anisotropy' / 'ChiPosMap.nii',\n",
    "    },\n",
    "    2: {  # Algorithm 3: APART-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'With_anisotropy' / 'X_para.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'Without_anisotropy' / 'X_para.nii',\n",
    "    },\n",
    "    3: {  # Algorithm 4: DECOMPOSE-QSM\n",
    "        'x_minus_with_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'With_anisotropy' / 'Results_PCS.nii',\n",
    "        'x_minus_without_anisotropy': base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'Without_anisotropy' / 'results_PCS.nii',\n",
    "    },\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), dpi=300)\n",
    "\n",
    "for idx in range(num_algorithms):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    algorithm_name = algorithm_names[idx]\n",
    "    \n",
    "    measured_with = nib.load(measured_maps[idx]['x_minus_with_anisotropy']).get_fdata() \n",
    "    measured_without = nib.load(measured_maps[idx]['x_minus_without_anisotropy']).get_fdata() \n",
    "\n",
    "    errors_with_regions = []\n",
    "    errors_without_regions = []\n",
    "    \n",
    "    for region in region_labels:\n",
    "        region_mask = segmentation2 == region\n",
    "        if np.any(region_mask):\n",
    "            # For \"With Anisotropy\"\n",
    "            sim_val_with = np.mean(simulated_with[region_mask])\n",
    "            meas_val_with = np.mean(measured_with[region_mask])\n",
    "            if sim_val_with != 0:\n",
    "                error_with = ((meas_val_with - sim_val_with) / sim_val_with) ** 2 * 100\n",
    "            else:\n",
    "                error_with = np.nan\n",
    "        \n",
    "            # For \"Without Anisotropy\"\n",
    "            sim_val_without = np.mean(simulated_without[region_mask])\n",
    "            meas_val_without = np.mean(measured_without[region_mask])\n",
    "            if sim_val_without != 0:\n",
    "                error_without = ((meas_val_without - sim_val_without) / sim_val_without) ** 2 * 100\n",
    "            else:\n",
    "                error_without = np.nan\n",
    "           \n",
    "            errors_with_regions.append(error_with)\n",
    "            errors_without_regions.append(error_without)\n",
    "    \n",
    "    # Convert to numpy arrays and remove NaNs\n",
    "    errors_with_regions = np.array(errors_with_regions)\n",
    "    errors_without_regions = np.array(errors_without_regions)\n",
    "    errors_with_regions = errors_with_regions[~np.isnan(errors_with_regions)]\n",
    "    errors_without_regions = errors_without_regions[~np.isnan(errors_without_regions)]\n",
    "    \n",
    "    x_vals = np.linspace(0, 70, 200)  \n",
    "    max_height = 0.4 \n",
    "    \n",
    "    # Plot KDE for \"With Anisotropy\"\n",
    "    if errors_with_regions.size > 1:\n",
    "        kde_with = gaussian_kde(errors_with_regions)\n",
    "        density_with = kde_with(x_vals)\n",
    "        scaling_with = max_height / np.max(density_with) if np.max(density_with) > 0 else 1\n",
    "        density_with_scaled = density_with * scaling_with\n",
    "        ax.fill_between(x_vals, 0, density_with_scaled, color='tab:blue', alpha=0.4)\n",
    "        ax.plot(x_vals, density_with_scaled, color='tab:blue', alpha=0.7)\n",
    "        mean_mspe_with = np.mean(errors_with_regions)\n",
    "    elif errors_with_regions.size == 1:\n",
    "        mean_mspe_with = errors_with_regions[0]\n",
    "        ax.plot([mean_mspe_with], [max_height/2], marker='o', color='tab:blue')\n",
    "    else:\n",
    "        mean_mspe_with = None  # no data available\n",
    "\n",
    "    # Plot KDE for \"Without Anisotropy\"\n",
    "    if errors_without_regions.size > 1:\n",
    "        kde_without = gaussian_kde(errors_without_regions)\n",
    "        density_without = kde_without(x_vals)\n",
    "        scaling_without = max_height / np.max(density_without) if np.max(density_without) > 0 else 1\n",
    "        density_without_scaled = density_without * scaling_without\n",
    "        ax.fill_between(x_vals, 0, density_without_scaled, color='tab:orange', alpha=0.4)\n",
    "        ax.plot(x_vals, density_without_scaled, color='tab:orange', alpha=0.7)\n",
    "        mean_mspe_without = np.mean(errors_without_regions)\n",
    "    elif errors_without_regions.size == 1:\n",
    "        mean_mspe_without = errors_without_regions[0]\n",
    "        ax.plot([mean_mspe_without], [max_height/2], marker='o', color='tab:orange')\n",
    "    else:\n",
    "        mean_mspe_without = None\n",
    "\n",
    "\n",
    "    if mean_mspe_with is not None:\n",
    "        ax.text(0.95, 0.8, f\"Mean MSPE: {mean_mspe_with:.1f}%\", transform=ax.transAxes,\n",
    "                color='tab:blue', ha='right', va='center', fontsize=12)\n",
    "    if mean_mspe_without is not None:\n",
    "        ax.text(0.95, 0.7, f\"Mean MSPE: {mean_mspe_without:.1f}%\", transform=ax.transAxes,\n",
    "                color='tab:orange', ha='right', va='center', fontsize=12)\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # Create and add a legend for the subplot\n",
    "    # ------------------------------------------------\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='tab:blue', lw=2, label='With Anisotropy'),\n",
    "        Line2D([0], [0], color='tab:orange', lw=2, label='Without Anisotropy')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    # Set title and axis labels.\n",
    "    ax.set_title(algorithm_name, fontsize=14)\n",
    "    ax.set_xlabel(\"MSPE (%) of $\\\\chi^+$\", fontsize=12)\n",
    "    ax.set_ylabel(\"Density (a.u.)\", fontsize=12)\n",
    "    #ax.set_xlim(0, 70)\n",
    "    ax.set_ylim(0, max_height * 1.2)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# ---------------------------\n",
    "# Final figure adjustments\n",
    "# ---------------------------\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"χ-separation\":   (base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'X-separation' / 'With_anisotropy' / 'ChiNegMap.nii',   base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' /'7T' /'X-separation' /'ChiNegMap.nii'),\n",
    "    \"R2*-QSM\":        (base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'R2star-QSM' / 'With_anisotropy' / 'ChiNegMap.nii',base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' /'7T' /'' 'R2star-QSM'/ 'ChiNegMap.nii'),\n",
    "    \"APART-QSM\":      (base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'APART-QSM' / 'With_anisotropy' / 'X_dia_abs.nii', base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / '7T' /'APART-QSM'  / 'X_dia_abs.nii'),\n",
    "    \"DECOMPOSE-QSM\":  (base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / 'DECOMPOSE-QSM' / 'With_anisotropy' / 'Results_DCS_abs.nii', base_dir / 'osfstorage' / 'Susceptibility_Separation_Results' / '7T' /'DECOMPOSE-QSM' / 'Results_DCS_abs.nii')\n",
    "}\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# Load segmentation file\n",
    "#-----------------------------------------------------------------\n",
    "segmentation_file = base_dir / \"osfstorage/Masks/white_matter_mask.nii.gz\"\n",
    "seg_nii  = nib.load(segmentation_file)\n",
    "seg_data = seg_nii.get_fdata()\n",
    "\n",
    "\n",
    "labels = range(1, 12)\n",
    "method_points = {}  \n",
    "all_mean_values = []\n",
    "all_difference_values = []\n",
    "\n",
    "for method_name, (nii_3T_path, nii_7T_path) in methods.items():\n",
    "    # --------------------\n",
    "    # Load the 3T and 7T\n",
    "    # --------------------\n",
    "    nii_3T = nib.load(nii_3T_path)\n",
    "    nii_7T = nib.load(nii_7T_path)\n",
    "    \n",
    "    data_3T = nii_3T.get_fdata()*-1\n",
    "    data_7T = nii_7T.get_fdata()*-1\n",
    "        \n",
    "    mean_values = np.zeros(len(labels))\n",
    "    diff_values = np.zeros(len(labels))\n",
    "    \n",
    "    for i, label_val in enumerate(labels):\n",
    "        # Mask for current region\n",
    "        mask = (seg_data == label_val)\n",
    "        \n",
    "        # Extract the region's data for 3T and 7T\n",
    "        region_3T = data_3T[mask]\n",
    "        region_7T = data_7T[mask]\n",
    "        \n",
    "        # Compute the mean within that region\n",
    "        mean_3T = np.mean(region_3T) if region_3T.size > 0 else np.nan\n",
    "        mean_7T = np.mean(region_7T) if region_7T.size > 0 else np.nan\n",
    "        \n",
    "        # Bland-Altman points\n",
    "        mean_values[i] = (mean_3T + mean_7T) / 2\n",
    "        diff_values[i] = (mean_3T - mean_7T)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    method_points[method_name] = (mean_values, diff_values)\n",
    "    \n",
    "    # Accumulate for global axis limits\n",
    "    all_mean_values.extend(mean_values)\n",
    "    all_difference_values.extend(diff_values)\n",
    "\n",
    "# Convert to NumPy for min/max\n",
    "all_mean_values = np.array(all_mean_values)\n",
    "all_difference_values = np.array(all_difference_values)\n",
    "\n",
    "x_min, x_max = np.min(all_mean_values), np.max(all_mean_values)\n",
    "x_margin = 0.1 * (x_max - x_min)  # 10% margin\n",
    "x_lim = (x_min - x_margin, x_max + x_margin)\n",
    "\n",
    "\n",
    "y_lim = (-0.05, 0.05)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (method_name, (mean_values, difference_values)) in zip(axes, method_points.items()):\n",
    "    # Mean and Limits of Agreement\n",
    "    mean_diff = np.mean(difference_values)\n",
    "    std_diff  = np.std(difference_values, ddof=1)\n",
    "    loa_upper = mean_diff + 1.96 * std_diff\n",
    "    loa_lower = mean_diff - 1.96 * std_diff\n",
    "    \n",
    "    # Scatter: 10 points per method\n",
    "    ax.scatter(mean_values, difference_values, color=\"blue\", marker=\"x\", s=50)\n",
    "    ax.axhline(mean_diff, color=\"red\", linestyle=\"--\", label=\"Mean difference\")\n",
    "    ax.axhline(loa_upper, color=\"green\", linestyle=\"--\", label=\"+1.96 SD\")\n",
    "    ax.axhline(loa_lower, color=\"green\", linestyle=\"--\", label=\"-1.96 SD\")\n",
    "    \n",
    "    ax.set_xlabel(r\"Mean of $\\chi^{3T}_{measured}$ and $\\chi^{7T}_{measured}$\")\n",
    "    ax.set_ylabel(r\"Difference $\\chi^{3T}_{measured} - \\chi^{7T}_{measured}$\")\n",
    "    ax.set_title(method_name)\n",
    "    \n",
    "    # Set global axis limits\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
